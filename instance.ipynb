{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本研究"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X=np.arange(-5,10,0.1)\n",
    "Y1=norm.pdf(X,1,3)\n",
    "Y2=norm.pdf(X,2,3)\n",
    "\n",
    "plt.plot(X,Y1,color=\"r\")\n",
    "plt.plot(X,Y2,color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPS6(ship_num,stack_num,height,n,size,beta,var):\n",
    "  O1=[i+1 for i in range(ship_num)]\n",
    "  S=[i+1 for i in range(stack_num)]\n",
    "  H=[i+1 for i in range(height)]\n",
    "  P=[i+1 for i in range(ship_num)]\n",
    "  f=stack_num*height-sum(n)\n",
    "\n",
    "  from asyncio.constants import SENDFILE_FALLBACK_READBUFFER_SIZE\n",
    "  import random\n",
    "  from random import seed\n",
    "  import numpy as np\n",
    "  from scipy.stats import multivariate_normal\n",
    "\n",
    "  # 期待値と分散共分散行列の準備\n",
    "  mean=np.arange(1,ship_num+1)\n",
    "  # a=list(a)\n",
    "  # a=random.sample(a,ship_num)\n",
    "  # mean=np.sort(a)\n",
    "  cov=np.zeros((ship_num,ship_num))\n",
    "  for i in range(ship_num):\n",
    "      for j in range(ship_num):\n",
    "          if i==j:\n",
    "              cov[i][i]=var*abs(np.random.randn())\n",
    "  for i in range(ship_num):\n",
    "      for j in range(ship_num):\n",
    "          if i!=j:\n",
    "              cov[i][j]=0\n",
    "\n",
    "  data_1 = np.random.multivariate_normal(mean, cov, size=size)\n",
    "\n",
    "  O_=np.argsort(data_1)\n",
    "  O_=O_+np.ones((size,ship_num)).astype(int)\n",
    "  O=O_.tolist()\n",
    "  # a=[]\n",
    "  # b={}\n",
    "  # for i in O:\n",
    "  #   # print(i)\n",
    "  #   if not i in a:\n",
    "  #     a.append(i)\n",
    "  #     for j in a:\n",
    "  #       b[tuple(j)]=O.count(j)\n",
    "\n",
    "  m=Model(\"IPS6\")\n",
    "\n",
    "  alpha=m.addVar(vtype=\"C\")\n",
    "\n",
    "  # 変数の定義\n",
    "  x,c,d={},{},{}\n",
    "  for s in S:\n",
    "    for h in H:\n",
    "      for p in P:\n",
    "        x[s,h,p]=m.addVar(vtype=\"B\")\n",
    "\n",
    "  for s in S:\n",
    "    for h in range(2,len(H)+1):\n",
    "      for i,o in enumerate(O):\n",
    "        c[s,h,i]=m.addVar(vtype=\"c\",lb=0)\n",
    "\n",
    "  for i in range(len(O)):\n",
    "    d[i]=m.addVar(vtype=\"C\",lb=0)\n",
    "\n",
    "  for p in P:\n",
    "    m.addConstr(quicksum(x[s,h,p] for s in S for h in H)==n[p-1])\n",
    "\n",
    "  for s in S:\n",
    "    for h in H:\n",
    "      m.addConstr(quicksum(x[s,h,p] for p in P)<=1)\n",
    "\n",
    "  for s in S:\n",
    "    for h in range(1,len(H)):\n",
    "      m.addConstr(quicksum(x[s,h+1,p] for p in P)<=quicksum(x[s,h,p] for p in P))\n",
    "\n",
    "  for s in S:\n",
    "    for h in range(2,len(H)+1):\n",
    "      for h_ in range(1,h):\n",
    "        for i,o in enumerate(O):\n",
    "          for j,p in enumerate(o):\n",
    "            m.addConstr(c[s,h,i]>=quicksum(x[s,h,k] for k in o[j:])-quicksum(x[s,h_,k] for k in o[j:]))\n",
    "\n",
    "  for i in range(len(O)):\n",
    "    m.addConstr(d[i]>=quicksum(c[s,h,i] for s in S for h in H if h!=1)-alpha)\n",
    "\n",
    "\n",
    "  m.setObjective(alpha+quicksum(d[i] for i in range(len(O)))/((1-beta)*len(O)))\n",
    "\n",
    "  if f>=height:\n",
    "    m.optimize()\n",
    "  else:\n",
    "    print(\"f<h\")\n",
    "\n",
    "  print(\"================================================\")\n",
    "\n",
    "# def result(self):\n",
    "  EPS=1.e-6\n",
    "\n",
    "  if m.Status == GRB.OPTIMAL:\n",
    "  # for (s,h,p,t) in x:\n",
    "  #   if t==len(T):\n",
    "  #     if x[s,h,p,t].X>EPS:\n",
    "  #       print(\"x[%2s,%2s,%2s,%2s]=%3s\" %(s,h,p,t,x[s,h,p,t].X)\n",
    "\n",
    "    for (s,h,i) in c:\n",
    "      if c[s,h,i].X>EPS:\n",
    "        print(\"c[%2s,%2s,%2s]=%3s  %4s\" %(s,h,i,c[s,h,i].X,O[i]))\n",
    "\n",
    "    global result\n",
    "    result=np.zeros((height,stack_num))\n",
    "    for (s,h,p) in x:\n",
    "      if x[s,h,p].X>EPS:\n",
    "    # print(\"x[%2s,%2s,%2s]=%3s  %4s\" %(s,h,p,x[s,h,p].X,O[i]))\n",
    "        result[height-h][s-1]=int(p)\n",
    "\n",
    "    result=result.astype(int)\n",
    "    print(\"VaR=\",alpha.X)\n",
    "    print(\"the objective function\", m.objVal)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    data_2 = np.random.multivariate_normal(mean, cov, size=size)\n",
    "\n",
    "    global OR\n",
    "    OR_=np.argsort(data_2)\n",
    "    OR_=OR_+np.ones((size,ship_num)).astype(int)\n",
    "    OR=OR_.tolist()\n",
    "\n",
    "    global penalty\n",
    "    penalty=[]\n",
    "    for k in OR:\n",
    "      O=k\n",
    "      a=0\n",
    "      for j in range(stack_num):\n",
    "          for i in range(1,height):\n",
    "              for i_ in range(i+1,height+1):\n",
    "                  if result[i-1][j]!=0 and result[i_-1][j]!=0:\n",
    "                      if O.index(result[i-1][j])>O.index(result[i_-1][j]):\n",
    "                          print(j+1,height-i+1,O)\n",
    "                          a+=1\n",
    "                          # print(\"penalty!\")\n",
    "                              # print(i,i_,j+1,O)\n",
    "                          break\n",
    "      penalty.append(a)\n",
    "      # print(a)\n",
    "    penalty=np.sort(penalty)\n",
    "    penalty=penalty[round(0.75*size):]\n",
    "    # penalty=penalty[round(0.8*size):]\n",
    "    # print(penalty)\n",
    "\n",
    "def robust(ship_num,stack_num,height,n,Gamma,size,var):\n",
    "    # nと初期配置を変更しなければいけない\n",
    "    num=sum(n)\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    O1=[i+1 for i in range(ship_num)]\n",
    "\n",
    "    Q=[i+1 for i in range(stack_num)]\n",
    "    L=[i+1 for i in range(height)]\n",
    "    P=[i+1 for i in range(ship_num)]\n",
    "    I=[i+1 for i in range(num)]\n",
    "    f=stack_num*height-len(I)\n",
    "    a=1\n",
    "    gamma=[]\n",
    "    for i in n:\n",
    "        for j in range(1,i+1):\n",
    "            gamma.append(a)\n",
    "        a+=1\n",
    "    \n",
    "    m=Model(\"BI\")\n",
    "\n",
    "    # 変数の定義\n",
    "    alpha,beta={},{}\n",
    "    for i in I:\n",
    "        for q in Q:\n",
    "            alpha[i,q]=m.addVar(vtype=\"B\")\n",
    "            beta[i,q]=m.addVar(vtype=\"B\")\n",
    "    J=[]\n",
    "    for i in I:\n",
    "        J.append([])\n",
    "        for j in I:\n",
    "            if gamma[i-1]<gamma[j-1]:\n",
    "                if gamma[j-1]-gamma[i-1]<=Gamma:\n",
    "                    J[i-1].append(j)\n",
    "\n",
    "    for q in Q:\n",
    "        m.addConstr(quicksum((alpha[i,q]+beta[i,q]) for i in I)<=len(L))\n",
    "\n",
    "    for i in I:\n",
    "        m.addConstr(quicksum((alpha[i,q]+beta[i,q]) for q in Q)==1)\n",
    "\n",
    "    for i in I:\n",
    "        for j in J[i-1]:\n",
    "            for q in Q:\n",
    "                m.addConstr(alpha[i,q]+alpha[j,q]+beta[j,q]<=1)\n",
    "\n",
    "    m.setObjective(quicksum(beta[i,q] for i in I for q in Q))\n",
    "\n",
    "    if f>=height:\n",
    "        m.optimize()\n",
    "\n",
    "    EPS=1.e-6\n",
    "\n",
    "    if m.Status == GRB.OPTIMAL:\n",
    "        print(\"====================================================\")\n",
    "        # for (s,h,p,t) in x:\n",
    "        #   if t==len(T):\n",
    "        #     if x[s,h,p,t].X>EPS:\n",
    "        #       print(\"x[%2s,%2s,%2s,%2s]=%3s\" %(s,h,p,t,x[s,h,p,t].X)\n",
    "\n",
    "        for (i,q) in beta:\n",
    "            if beta[i,q].X>EPS:\n",
    "                print(\"beta[%2s,%2s]=%3s\" %(gamma[i-1],q,beta[i,q].X))\n",
    "\n",
    "        EPS=1.e-6\n",
    "        a=[]\n",
    "        for q in Q:\n",
    "            a.append([])\n",
    "        for (i,q) in alpha:\n",
    "            if alpha[i,q].X>EPS:\n",
    "                a[q-1].append(gamma[i-1])\n",
    "        \n",
    "        for (i,q) in beta:\n",
    "            if beta[i,q].X>EPS:\n",
    "                a[q-1].append(gamma[i-1])\n",
    "\n",
    "        for q in Q:\n",
    "            a[q-1]=sorted(a[q-1],reverse=True)\n",
    "\n",
    "        global result_r\n",
    "        result_r=np.zeros((height,stack_num))\n",
    "        for q in Q:\n",
    "            for i,r in enumerate(a[q-1]):\n",
    "                result_r[height-i-1][q-1]=r\n",
    "            # print(i,r)\n",
    "\n",
    "        result_r=result_r.astype(int)\n",
    "        \n",
    "        print(result_r)\n",
    "        print(\"the objective function\", m.objVal)\n",
    "\n",
    "        from asyncio.constants import SENDFILE_FALLBACK_READBUFFER_SIZE\n",
    "        import random\n",
    "        from random import seed\n",
    "        import numpy as np\n",
    "        from scipy.stats import multivariate_normal\n",
    "\n",
    "        # 期待値と分散共分散行列の準備\n",
    "        mean=np.arange(1,ship_num+1)\n",
    "        # a=list(a)\n",
    "        # a=random.sample(a,ship_num)\n",
    "        # mean=np.sort(a)\n",
    "        cov=np.zeros((ship_num,ship_num))\n",
    "        for i in range(ship_num):\n",
    "            for j in range(ship_num):\n",
    "                if i==j:\n",
    "                    cov[i][i]=var*abs(np.random.randn())\n",
    "        for i in range(ship_num):\n",
    "            for j in range(ship_num):\n",
    "                if i!=j:\n",
    "                    cov[i][j]=0\n",
    "\n",
    "        data_1 = np.random.multivariate_normal(mean, cov, size=size)\n",
    "\n",
    "        O_=np.argsort(data_1)\n",
    "        O_=O_+np.ones((size,ship_num)).astype(int)\n",
    "        OR=O_.tolist()\n",
    "\n",
    "\n",
    "        global penalty_r\n",
    "        penalty_r=[]\n",
    "        for k in OR:\n",
    "            O=k\n",
    "            a=0\n",
    "            for j in range(stack_num):\n",
    "                for i in range(1,height):\n",
    "                    for i_ in range(i+1,height+1):\n",
    "                        if result_r[i-1][j]!=0 and result_r[i_-1][j]!=0:\n",
    "                            if O.index(result_r[i-1][j])>O.index(result_r[i_-1][j]):\n",
    "                                print(j+1,height-i+1,O)\n",
    "                                a+=1\n",
    "                                # print(\"penalty!\")\n",
    "                                # print(i,i_,j+1,O)\n",
    "                                break\n",
    "            penalty_r.append(a)\n",
    "        \n",
    "        penalty_r=np.sort(penalty_r)\n",
    "        penalty_r=penalty_r[round(0.75*size):]\n",
    "        print(penalty_r)\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # plt.boxplot(penalty_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 50155 rows, 2351 columns and 603100 nonzeros\n",
      "Model fingerprint: 0x1a9d295c\n",
      "Variable types: 2101 continuous, 250 integer (250 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [4e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+00]\n",
      "Presolve removed 3006 rows and 126 columns\n",
      "Presolve time: 2.00s\n",
      "Presolved: 47149 rows, 2225 columns, 566968 nonzeros\n",
      "Variable types: 1975 continuous, 250 integer (250 binary)\n",
      "\n",
      "Use crossover to convert LP symmetric solution to basic solution...\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 413 iterations, 0.64 seconds (0.49 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   17          -    0.00000      -     -    4s\n",
      "H    0     0                       4.0000000    0.00000   100%     -    4s\n",
      "     0     0    0.00000    0   23    4.00000    0.00000   100%     -    6s\n",
      "H    0     0                       2.0000000    0.00000   100%     -    6s\n",
      "     0     0    0.00000    0   11    2.00000    0.00000   100%     -    9s\n",
      "H    0     0                       1.2000000    0.00000   100%     -   10s\n",
      "     0     0    0.00000    0   12    1.20000    0.00000   100%     -   11s\n",
      "H    0     0                       0.4000000    0.00000   100%     -   11s\n",
      "     0     0    0.00000    0   12    0.40000    0.00000   100%     -   12s\n",
      "     0     2    0.00000    0   12    0.40000    0.00000   100%     -   16s\n",
      "     7    12    0.00000    3   46    0.40000    0.00000   100%   370   20s\n",
      "    15    20    0.03200    5   33    0.40000    0.00000   100%   715   30s\n",
      "    19    22     cutoff    5         0.40000    0.00000   100%  1260   49s\n",
      "    23    26    0.24000    6   31    0.40000    0.00000   100%  1263   54s\n",
      "    27    26    0.25600    7   22    0.40000    0.00000   100%  1296   66s\n",
      "    31    29 infeasible    7         0.40000    0.00000   100%  1376   77s\n",
      "    42    34     cutoff    8         0.40000    0.00000   100%  1197   85s\n",
      "    53    41    0.00000    4   42    0.40000    0.00000   100%  1210   90s\n",
      "    62    41    0.01933    5   36    0.40000    0.00000   100%  1087   95s\n",
      "    74    41    0.10400    5   52    0.40000    0.00000   100%   982  104s\n",
      "    84    47    0.00000    5   28    0.40000    0.00000   100%   928  110s\n",
      "    90    44     cutoff    6         0.40000    0.00000   100%   993  124s\n",
      "    97    49     cutoff    5         0.40000    0.00000   100%  1153  137s\n",
      "   104    48    0.34564    6   54    0.40000    0.00000   100%  1133  143s\n",
      "   111    45    0.16000    6   38    0.40000    0.00000   100%  1110  153s\n",
      "   124    47    0.20000    8   17    0.40000    0.00000   100%  1075  159s\n",
      "   136    47    0.30933    8   44    0.40000    0.00000   100%  1033  173s\n",
      "   142    43     cutoff    9         0.40000    0.00000   100%  1112  189s\n",
      "   156    48    0.17965    7   46    0.40000    0.00000   100%  1154  201s\n",
      "   161    49    0.33091    8   45    0.40000    0.00000   100%  1256  209s\n",
      "   166    47     cutoff    9         0.40000    0.00000   100%  1278  214s\n",
      "   172    40    0.25400    8   45    0.40000    0.00000   100%  1258  230s\n",
      "   183    45    0.12400    7   46    0.40000    0.00000   100%  1328  240s\n",
      "   190    46 infeasible   10         0.40000    0.00000   100%  1336  264s\n",
      "   201    48    0.39067   10   28    0.40000    0.00000   100%  1407  273s\n",
      "   205    47    0.39333   11   35    0.40000    0.00000   100%  1411  281s\n",
      "   222    55    0.03200    5   15    0.40000    0.00000   100%  1353  287s\n",
      "H  242    55                       0.3200000    0.00000   100%  1255  287s\n",
      "   256    58     cutoff   16         0.32000    0.00000   100%  1206  295s\n",
      "   279    61    0.24000    6   33    0.32000    0.01030  96.8%  1150  304s\n",
      "H  285    61                       0.2400000    0.01030  95.7%  1129  304s\n",
      "   324    55     cutoff   12         0.24000    0.01889  92.1%  1022  323s\n",
      "   344    48 infeasible    8         0.24000    0.03222  86.6%  1020  332s\n",
      "   375    35     cutoff    8         0.24000    0.05867  75.6%   968  363s\n",
      "   408    12 infeasible    9         0.24000    0.10545  56.1%   979  371s\n",
      "*  436    12              12       0.1600000    0.10667  33.3%   940  371s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 2\n",
      "  RLT: 12\n",
      "\n",
      "Explored 457 nodes (416668 simplex iterations) in 372.86 seconds (615.55 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 7: 0.16 0.24 0.32 ... 4\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.600000000000e-01, best bound 1.600000000000e-01, gap 0.0000%\n",
      "================================================\n",
      "c[ 1, 3,38]=1.0  [2, 6, 3, 4, 1, 5, 7, 8, 9, 10]\n",
      "c[ 1, 3,43]=1.0  [6, 1, 4, 5, 2, 3, 7, 8, 9, 10]\n",
      "c[ 1, 3,65]=1.0  [2, 4, 6, 3, 1, 5, 8, 7, 9, 10]\n",
      "c[ 5, 5,86]=1.0  [2, 5, 3, 4, 1, 6, 7, 10, 8, 9]\n",
      "VaR= 0.0\n",
      "the objective function 0.16\n",
      "[[ 0  0  0  0  1]\n",
      " [ 0  2  4  3  5]\n",
      " [ 1  2  4  3  5]\n",
      " [ 6  7  9  8 10]\n",
      " [ 6  7  9  8 10]]\n",
      "1 3 [2, 4, 3, 5, 6, 1, 8, 7, 9, 10]\n",
      "5 5 [2, 4, 3, 5, 6, 1, 8, 7, 9, 10]\n",
      "5 5 [5, 4, 1, 2, 3, 7, 6, 10, 8, 9]\n",
      "2 4 [1, 7, 2, 3, 5, 4, 8, 6, 10, 9]\n",
      "2 3 [1, 7, 2, 3, 5, 4, 8, 6, 10, 9]\n",
      "3 4 [1, 2, 3, 5, 9, 7, 4, 8, 6, 10]\n",
      "3 3 [1, 2, 3, 5, 9, 7, 4, 8, 6, 10]\n",
      "1 3 [2, 3, 4, 6, 1, 5, 9, 7, 8, 10]\n",
      "1 3 [2, 3, 5, 6, 4, 1, 7, 9, 10, 8]\n",
      "5 5 [2, 3, 5, 6, 4, 1, 7, 9, 10, 8]\n",
      "5 5 [2, 5, 1, 3, 4, 7, 6, 9, 10, 8]\n",
      "1 3 [5, 2, 6, 3, 4, 8, 1, 7, 10, 9]\n",
      "5 5 [5, 2, 6, 3, 4, 8, 1, 7, 10, 9]\n",
      "1 3 [2, 3, 6, 1, 5, 4, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "size=100\n",
    "var=2.5\n",
    "inst=[[5,5,[2,2,2,2,2,2,2,2,2,2]]]\n",
    "pcvar=[]\n",
    "for i in inst:\n",
    "  ship_num=len(i[2])\n",
    "  IPS6(ship_num,i[0],i[1],i[2],size,0.75,var)\n",
    "  pcvar+=list(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 205 rows, 200 columns and 940 nonzeros\n",
      "Model fingerprint: 0xdc7990cf\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Found heuristic solution: objective 16.0000000\n",
      "Presolve removed 0 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 205 rows, 190 columns, 900 nonzeros\n",
      "Found heuristic solution: objective 0.0000000\n",
      "Variable types: 0 continuous, 190 integer (190 binary)\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 0 16 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[ 2  1  6  5  0]\n",
      " [ 2  1  6  5  0]\n",
      " [ 4  3  8  7  0]\n",
      " [ 4  3 10  7  0]\n",
      " [ 8  9 10  9  0]]\n",
      "the objective function 0.0\n",
      "3 5 [1, 2, 5, 4, 3, 7, 8, 6, 9, 10]\n",
      "3 4 [1, 2, 5, 4, 3, 7, 8, 6, 9, 10]\n",
      "2 5 [3, 2, 4, 1, 5, 7, 8, 9, 10, 6]\n",
      "2 4 [3, 2, 4, 1, 5, 7, 8, 9, 10, 6]\n",
      "3 5 [3, 2, 4, 1, 5, 7, 8, 9, 10, 6]\n",
      "3 4 [3, 2, 4, 1, 5, 7, 8, 9, 10, 6]\n",
      "1 5 [1, 4, 2, 5, 3, 7, 6, 9, 10, 8]\n",
      "1 4 [1, 4, 2, 5, 3, 7, 6, 9, 10, 8]\n",
      "3 3 [1, 4, 2, 5, 3, 7, 6, 9, 10, 8]\n",
      "2 5 [2, 3, 4, 1, 6, 5, 8, 7, 9, 10]\n",
      "2 4 [2, 3, 4, 1, 6, 5, 8, 7, 9, 10]\n",
      "3 5 [2, 1, 3, 5, 7, 4, 8, 6, 9, 10]\n",
      "3 4 [2, 1, 3, 5, 7, 4, 8, 6, 9, 10]\n",
      "4 3 [1, 2, 3, 5, 6, 4, 8, 9, 10, 7]\n",
      "4 2 [1, 2, 3, 5, 6, 4, 8, 9, 10, 7]\n",
      "2 5 [2, 3, 1, 6, 4, 5, 8, 9, 7, 10]\n",
      "2 4 [2, 3, 1, 6, 4, 5, 8, 9, 7, 10]\n",
      "4 3 [2, 3, 1, 6, 4, 5, 8, 9, 7, 10]\n",
      "4 2 [2, 3, 1, 6, 4, 5, 8, 9, 7, 10]\n",
      "4 3 [1, 3, 2, 4, 5, 6, 8, 9, 7, 10]\n",
      "4 2 [1, 3, 2, 4, 5, 6, 8, 9, 7, 10]\n",
      "1 3 [1, 3, 2, 8, 5, 4, 7, 9, 6, 10]\n",
      "1 2 [1, 3, 2, 8, 5, 4, 7, 9, 6, 10]\n",
      "3 5 [1, 3, 2, 8, 5, 4, 7, 9, 6, 10]\n",
      "3 4 [1, 3, 2, 8, 5, 4, 7, 9, 6, 10]\n",
      "3 3 [2, 1, 3, 4, 5, 6, 7, 9, 10, 8]\n",
      "4 3 [2, 4, 1, 6, 5, 3, 8, 9, 7, 10]\n",
      "4 2 [2, 4, 1, 6, 5, 3, 8, 9, 7, 10]\n",
      "1 3 [1, 2, 3, 6, 8, 5, 4, 7, 10, 9]\n",
      "1 2 [1, 2, 3, 6, 8, 5, 4, 7, 10, 9]\n",
      "2 5 [3, 1, 2, 4, 7, 5, 8, 10, 9, 6]\n",
      "2 4 [3, 1, 2, 4, 7, 5, 8, 10, 9, 6]\n",
      "3 5 [3, 1, 2, 4, 7, 5, 8, 10, 9, 6]\n",
      "3 4 [3, 1, 2, 4, 7, 5, 8, 10, 9, 6]\n",
      "4 5 [3, 1, 2, 4, 7, 5, 8, 10, 9, 6]\n",
      "4 4 [3, 1, 2, 4, 7, 5, 8, 10, 9, 6]\n",
      "4 5 [1, 3, 2, 4, 7, 5, 6, 8, 9, 10]\n",
      "4 4 [1, 3, 2, 4, 7, 5, 6, 8, 9, 10]\n",
      "2 5 [3, 2, 1, 4, 5, 6, 7, 10, 8, 9]\n",
      "2 4 [3, 2, 1, 4, 5, 6, 7, 10, 8, 9]\n",
      "3 3 [3, 2, 1, 4, 5, 6, 7, 10, 8, 9]\n",
      "3 5 [1, 2, 3, 4, 5, 7, 8, 6, 9, 10]\n",
      "3 4 [1, 2, 3, 4, 5, 7, 8, 6, 9, 10]\n",
      "1 5 [1, 4, 2, 5, 3, 7, 6, 8, 10, 9]\n",
      "1 4 [1, 4, 2, 5, 3, 7, 6, 8, 10, 9]\n",
      "1 3 [1, 3, 2, 6, 5, 8, 4, 7, 9, 10]\n",
      "1 2 [1, 3, 2, 6, 5, 8, 4, 7, 9, 10]\n",
      "4 5 [1, 2, 4, 7, 3, 5, 6, 8, 9, 10]\n",
      "4 4 [1, 2, 4, 7, 3, 5, 6, 8, 9, 10]\n",
      "2 5 [3, 2, 1, 4, 6, 8, 5, 7, 9, 10]\n",
      "2 4 [3, 2, 1, 4, 6, 8, 5, 7, 9, 10]\n",
      "1 5 [1, 3, 4, 6, 2, 5, 7, 8, 9, 10]\n",
      "1 4 [1, 3, 4, 6, 2, 5, 7, 8, 9, 10]\n",
      "3 3 [1, 2, 6, 4, 5, 3, 7, 9, 10, 8]\n",
      "3 5 [1, 2, 4, 3, 5, 7, 8, 6, 9, 10]\n",
      "3 4 [1, 2, 4, 3, 5, 7, 8, 6, 9, 10]\n",
      "1 5 [1, 4, 2, 6, 5, 8, 3, 7, 9, 10]\n",
      "1 4 [1, 4, 2, 6, 5, 8, 3, 7, 9, 10]\n",
      "1 3 [2, 1, 3, 5, 6, 8, 4, 7, 9, 10]\n",
      "1 2 [2, 1, 3, 5, 6, 8, 4, 7, 9, 10]\n",
      "1 5 [1, 4, 3, 5, 2, 6, 8, 7, 9, 10]\n",
      "1 4 [1, 4, 3, 5, 2, 6, 8, 7, 9, 10]\n",
      "3 3 [2, 1, 3, 4, 6, 5, 7, 9, 10, 8]\n",
      "1 5 [1, 3, 4, 2, 8, 5, 7, 6, 9, 10]\n",
      "1 4 [1, 3, 4, 2, 8, 5, 7, 6, 9, 10]\n",
      "3 5 [1, 3, 4, 2, 8, 5, 7, 6, 9, 10]\n",
      "3 4 [1, 3, 4, 2, 8, 5, 7, 6, 9, 10]\n",
      "2 5 [3, 2, 1, 5, 4, 6, 8, 7, 9, 10]\n",
      "2 4 [3, 2, 1, 5, 4, 6, 8, 7, 9, 10]\n",
      "1 5 [4, 3, 2, 1, 5, 6, 8, 9, 7, 10]\n",
      "1 4 [4, 3, 2, 1, 5, 6, 8, 9, 7, 10]\n",
      "2 5 [4, 3, 2, 1, 5, 6, 8, 9, 7, 10]\n",
      "2 4 [4, 3, 2, 1, 5, 6, 8, 9, 7, 10]\n",
      "4 3 [4, 3, 2, 1, 5, 6, 8, 9, 7, 10]\n",
      "4 2 [4, 3, 2, 1, 5, 6, 8, 9, 7, 10]\n",
      "3 5 [1, 2, 3, 4, 5, 8, 7, 6, 9, 10]\n",
      "3 4 [1, 2, 3, 4, 5, 8, 7, 6, 9, 10]\n",
      "4 5 [2, 1, 4, 3, 7, 6, 5, 8, 9, 10]\n",
      "4 4 [2, 1, 4, 3, 7, 6, 5, 8, 9, 10]\n",
      "1 3 [3, 1, 2, 6, 5, 8, 7, 4, 9, 10]\n",
      "1 2 [3, 1, 2, 6, 5, 8, 7, 4, 9, 10]\n",
      "2 5 [3, 1, 2, 6, 5, 8, 7, 4, 9, 10]\n",
      "2 4 [3, 1, 2, 6, 5, 8, 7, 4, 9, 10]\n",
      "1 3 [1, 2, 3, 8, 5, 4, 7, 6, 9, 10]\n",
      "1 2 [1, 2, 3, 8, 5, 4, 7, 6, 9, 10]\n",
      "3 5 [1, 2, 3, 8, 5, 4, 7, 6, 9, 10]\n",
      "3 4 [1, 2, 3, 8, 5, 4, 7, 6, 9, 10]\n",
      "1 5 [1, 4, 2, 3, 6, 7, 5, 8, 9, 10]\n",
      "1 4 [1, 4, 2, 3, 6, 7, 5, 8, 9, 10]\n",
      "4 5 [1, 4, 2, 3, 6, 7, 5, 8, 9, 10]\n",
      "4 4 [1, 4, 2, 3, 6, 7, 5, 8, 9, 10]\n",
      "3 5 [2, 4, 1, 5, 3, 7, 8, 6, 9, 10]\n",
      "3 4 [2, 4, 1, 5, 3, 7, 8, 6, 9, 10]\n",
      "3 3 [2, 1, 3, 5, 4, 6, 7, 9, 10, 8]\n",
      "2 5 [3, 1, 5, 2, 7, 4, 6, 8, 10, 9]\n",
      "2 4 [3, 1, 5, 2, 7, 4, 6, 8, 10, 9]\n",
      "2 5 [3, 2, 1, 4, 5, 6, 8, 7, 9, 10]\n",
      "2 4 [3, 2, 1, 4, 5, 6, 8, 7, 9, 10]\n",
      "2 5 [3, 2, 1, 4, 5, 6, 8, 7, 10, 9]\n",
      "2 4 [3, 2, 1, 4, 5, 6, 8, 7, 10, 9]\n",
      "4 5 [1, 3, 2, 6, 4, 7, 5, 8, 9, 10]\n",
      "4 4 [1, 3, 2, 6, 4, 7, 5, 8, 9, 10]\n",
      "4 3 [1, 2, 3, 6, 5, 4, 8, 10, 9, 7]\n",
      "4 2 [1, 2, 3, 6, 5, 4, 8, 10, 9, 7]\n",
      "2 5 [3, 1, 2, 6, 5, 4, 7, 8, 9, 10]\n",
      "2 4 [3, 1, 2, 6, 5, 4, 7, 8, 9, 10]\n",
      "1 5 [1, 4, 2, 3, 6, 5, 7, 10, 8, 9]\n",
      "1 4 [1, 4, 2, 3, 6, 5, 7, 10, 8, 9]\n",
      "3 3 [1, 4, 2, 3, 6, 5, 7, 10, 8, 9]\n",
      "3 5 [1, 2, 3, 4, 5, 7, 8, 6, 9, 10]\n",
      "3 4 [1, 2, 3, 4, 5, 7, 8, 6, 9, 10]\n",
      "4 3 [1, 3, 2, 5, 6, 4, 8, 9, 7, 10]\n",
      "4 2 [1, 3, 2, 5, 6, 4, 8, 9, 7, 10]\n",
      "3 5 [2, 1, 5, 7, 3, 4, 8, 6, 9, 10]\n",
      "3 4 [2, 1, 5, 7, 3, 4, 8, 6, 9, 10]\n",
      "2 5 [3, 1, 2, 4, 6, 5, 7, 8, 10, 9]\n",
      "2 4 [3, 1, 2, 4, 6, 5, 7, 8, 10, 9]\n",
      "3 5 [2, 1, 3, 4, 5, 7, 8, 9, 6, 10]\n",
      "3 4 [2, 1, 3, 4, 5, 7, 8, 9, 6, 10]\n",
      "2 5 [3, 1, 6, 2, 4, 5, 7, 8, 9, 10]\n",
      "2 4 [3, 1, 6, 2, 4, 5, 7, 8, 9, 10]\n",
      "1 3 [2, 3, 1, 5, 7, 8, 4, 6, 9, 10]\n",
      "1 2 [2, 3, 1, 5, 7, 8, 4, 6, 9, 10]\n",
      "2 5 [2, 3, 1, 5, 7, 8, 4, 6, 9, 10]\n",
      "2 4 [2, 3, 1, 5, 7, 8, 4, 6, 9, 10]\n",
      "3 5 [2, 3, 1, 5, 7, 8, 4, 6, 9, 10]\n",
      "3 4 [2, 3, 1, 5, 7, 8, 4, 6, 9, 10]\n",
      "2 5 [3, 2, 1, 4, 7, 5, 8, 6, 9, 10]\n",
      "2 4 [3, 2, 1, 4, 7, 5, 8, 6, 9, 10]\n",
      "3 5 [3, 2, 1, 4, 7, 5, 8, 6, 9, 10]\n",
      "3 4 [3, 2, 1, 4, 7, 5, 8, 6, 9, 10]\n",
      "4 5 [3, 2, 1, 4, 7, 5, 8, 6, 9, 10]\n",
      "4 4 [3, 2, 1, 4, 7, 5, 8, 6, 9, 10]\n",
      "1 5 [1, 3, 5, 4, 2, 6, 7, 9, 8, 10]\n",
      "1 4 [1, 3, 5, 4, 2, 6, 7, 9, 8, 10]\n",
      "3 5 [1, 3, 2, 5, 4, 8, 6, 7, 9, 10]\n",
      "3 4 [1, 3, 2, 5, 4, 8, 6, 7, 9, 10]\n",
      "3 5 [1, 2, 4, 3, 5, 7, 8, 6, 9, 10]\n",
      "3 4 [1, 2, 4, 3, 5, 7, 8, 6, 9, 10]\n",
      "2 5 [3, 1, 2, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 4 [3, 1, 2, 4, 6, 5, 8, 7, 9, 10]\n",
      "1 3 [1, 3, 5, 2, 8, 4, 7, 6, 9, 10]\n",
      "1 2 [1, 3, 5, 2, 8, 4, 7, 6, 9, 10]\n",
      "3 5 [1, 3, 5, 2, 8, 4, 7, 6, 9, 10]\n",
      "3 4 [1, 3, 5, 2, 8, 4, 7, 6, 9, 10]\n",
      "3 3 [1, 6, 7, 2, 5, 3, 4, 9, 10, 8]\n",
      "4 5 [1, 6, 7, 2, 5, 3, 4, 9, 10, 8]\n",
      "4 4 [1, 6, 7, 2, 5, 3, 4, 9, 10, 8]\n",
      "2 5 [3, 1, 2, 5, 6, 4, 7, 10, 9, 8]\n",
      "2 4 [3, 1, 2, 5, 6, 4, 7, 10, 9, 8]\n",
      "3 3 [3, 1, 2, 5, 6, 4, 7, 10, 9, 8]\n",
      "2 5 [3, 2, 1, 5, 4, 7, 6, 9, 8, 10]\n",
      "2 4 [3, 2, 1, 5, 4, 7, 6, 9, 8, 10]\n",
      "1 3 [2, 1, 3, 8, 5, 4, 6, 7, 9, 10]\n",
      "1 2 [2, 1, 3, 8, 5, 4, 6, 7, 9, 10]\n",
      "3 5 [2, 1, 3, 8, 5, 4, 6, 7, 9, 10]\n",
      "3 4 [2, 1, 3, 8, 5, 4, 6, 7, 9, 10]\n",
      "3 5 [1, 2, 3, 4, 7, 5, 8, 6, 9, 10]\n",
      "3 4 [1, 2, 3, 4, 7, 5, 8, 6, 9, 10]\n",
      "4 5 [1, 2, 3, 4, 7, 5, 8, 6, 9, 10]\n",
      "4 4 [1, 2, 3, 4, 7, 5, 8, 6, 9, 10]\n",
      "1 3 [1, 2, 3, 5, 7, 8, 4, 6, 9, 10]\n",
      "1 2 [1, 2, 3, 5, 7, 8, 4, 6, 9, 10]\n",
      "3 5 [1, 2, 3, 5, 7, 8, 4, 6, 9, 10]\n",
      "3 4 [1, 2, 3, 5, 7, 8, 4, 6, 9, 10]\n",
      "1 5 [4, 1, 3, 2, 6, 5, 7, 10, 9, 8]\n",
      "1 4 [4, 1, 3, 2, 6, 5, 7, 10, 9, 8]\n",
      "3 3 [4, 1, 3, 2, 6, 5, 7, 10, 9, 8]\n",
      "3 5 [1, 3, 5, 2, 4, 8, 10, 7, 6, 9]\n",
      "3 4 [1, 3, 5, 2, 4, 8, 10, 7, 6, 9]\n",
      "[2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6]\n",
      "[2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6]\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 365 rows, 200 columns and 1420 nonzeros\n",
      "Model fingerprint: 0xbedad61c\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Found heuristic solution: objective 16.0000000\n",
      "Presolve removed 120 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 245 rows, 190 columns, 1220 nonzeros\n",
      "Found heuristic solution: objective 3.0000000\n",
      "Variable types: 0 continuous, 190 integer (190 binary)\n",
      "Found heuristic solution: objective 1.0000000\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 54 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (54 simplex iterations) in 0.05 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 0 1 3 16 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[ 3  0  0  1  2]\n",
      " [ 3  0  0  1  6]\n",
      " [ 7  0  2  5  6]\n",
      " [ 7  4  5  8  9]\n",
      " [10  4 10  8  9]]\n",
      "the objective function 0.0\n",
      "1 5 [1, 2, 7, 3, 4, 6, 5, 10, 8, 9]\n",
      "1 4 [1, 2, 7, 3, 4, 6, 5, 10, 8, 9]\n",
      "4 3 [1, 2, 3, 4, 8, 6, 7, 5, 9, 10]\n",
      "5 4 [1, 2, 3, 4, 9, 5, 6, 7, 8, 10]\n",
      "5 3 [1, 2, 3, 4, 9, 5, 6, 7, 8, 10]\n",
      "5 4 [2, 1, 3, 5, 4, 9, 6, 7, 8, 10]\n",
      "5 3 [2, 1, 3, 5, 4, 9, 6, 7, 8, 10]\n",
      "1 3 [2, 1, 3, 4, 5, 6, 9, 8, 10, 7]\n",
      "1 2 [2, 1, 3, 4, 5, 6, 9, 8, 10, 7]\n",
      "4 3 [2, 1, 4, 3, 7, 6, 8, 5, 9, 10]\n",
      "5 4 [1, 2, 3, 7, 4, 9, 5, 6, 8, 10]\n",
      "5 3 [1, 2, 3, 7, 4, 9, 5, 6, 8, 10]\n",
      "1 3 [2, 1, 4, 5, 3, 6, 8, 10, 9, 7]\n",
      "1 2 [2, 1, 4, 5, 3, 6, 8, 10, 9, 7]\n",
      "1 5 [2, 1, 7, 4, 5, 3, 6, 10, 8, 9]\n",
      "1 4 [2, 1, 7, 4, 5, 3, 6, 10, 8, 9]\n",
      "5 4 [1, 2, 3, 5, 4, 8, 9, 7, 6, 10]\n",
      "5 3 [1, 2, 3, 5, 4, 8, 9, 7, 6, 10]\n",
      "4 3 [1, 2, 3, 4, 8, 6, 5, 7, 9, 10]\n",
      "1 3 [1, 2, 3, 5, 4, 6, 8, 10, 9, 7]\n",
      "1 2 [1, 2, 3, 5, 4, 6, 8, 10, 9, 7]\n",
      "1 3 [1, 2, 3, 5, 4, 6, 9, 8, 10, 7]\n",
      "1 2 [1, 2, 3, 5, 4, 6, 9, 8, 10, 7]\n",
      "1 5 [1, 2, 7, 4, 5, 3, 6, 8, 9, 10]\n",
      "1 4 [1, 2, 7, 4, 5, 3, 6, 8, 9, 10]\n",
      "1 3 [1, 2, 4, 3, 5, 8, 6, 9, 10, 7]\n",
      "1 2 [1, 2, 4, 3, 5, 8, 6, 9, 10, 7]\n",
      "3 3 [1, 3, 5, 4, 2, 9, 6, 7, 8, 10]\n",
      "5 4 [1, 3, 5, 4, 2, 9, 6, 7, 8, 10]\n",
      "5 3 [1, 3, 5, 4, 2, 9, 6, 7, 8, 10]\n",
      "1 5 [1, 4, 2, 7, 5, 3, 6, 9, 8, 10]\n",
      "1 4 [1, 4, 2, 7, 5, 3, 6, 9, 8, 10]\n",
      "1 3 [1, 2, 5, 3, 4, 6, 8, 10, 7, 9]\n",
      "1 2 [1, 2, 5, 3, 4, 6, 8, 10, 7, 9]\n",
      "[0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3]\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 505 rows, 200 columns and 1840 nonzeros\n",
      "Model fingerprint: 0xe5ec51d3\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Found heuristic solution: objective 16.0000000\n",
      "Presolve removed 210 rows and 10 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 295 rows, 190 columns, 1620 nonzeros\n",
      "Found heuristic solution: objective 3.0000000\n",
      "Variable types: 0 continuous, 190 integer (190 binary)\n",
      "Found heuristic solution: objective 1.0000000\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       0.0000000    0.00000  0.00%     -    0s\n",
      "     0     0    0.00000    0   40    0.00000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (97 simplex iterations) in 0.04 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 0 1 3 16 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[ 0  0  1  2  0]\n",
      " [ 3  0  5  2  0]\n",
      " [ 3  4  5  6  1]\n",
      " [ 7  4  9  6  8]\n",
      " [ 7 10  9 10  8]]\n",
      "the objective function 0.0\n",
      "3 5 [5, 1, 2, 4, 3, 7, 6, 8, 9, 10]\n",
      "3 4 [1, 2, 3, 4, 6, 7, 8, 9, 5, 10]\n",
      "3 3 [1, 2, 3, 4, 6, 7, 8, 9, 5, 10]\n",
      "4 5 [1, 5, 6, 3, 2, 4, 8, 7, 9, 10]\n",
      "4 4 [1, 5, 6, 3, 2, 4, 8, 7, 9, 10]\n",
      "4 3 [1, 4, 2, 3, 5, 7, 10, 6, 8, 9]\n",
      "4 2 [1, 4, 2, 3, 5, 7, 10, 6, 8, 9]\n",
      "3 4 [2, 3, 1, 6, 4, 7, 8, 9, 10, 5]\n",
      "3 3 [2, 3, 1, 6, 4, 7, 8, 9, 10, 5]\n",
      "4 5 [1, 6, 2, 4, 3, 5, 7, 8, 9, 10]\n",
      "4 4 [1, 6, 2, 4, 3, 5, 7, 8, 9, 10]\n",
      "3 4 [3, 2, 1, 4, 7, 9, 6, 8, 5, 10]\n",
      "3 3 [3, 2, 1, 4, 7, 9, 6, 8, 5, 10]\n",
      "4 5 [1, 3, 4, 6, 2, 5, 8, 7, 10, 9]\n",
      "4 4 [1, 3, 4, 6, 2, 5, 8, 7, 10, 9]\n",
      "3 4 [1, 2, 3, 4, 9, 7, 5, 6, 8, 10]\n",
      "3 3 [1, 2, 3, 4, 9, 7, 5, 6, 8, 10]\n",
      "4 3 [2, 1, 3, 4, 5, 7, 10, 6, 8, 9]\n",
      "4 2 [2, 1, 3, 4, 5, 7, 10, 6, 8, 9]\n",
      "3 4 [1, 3, 2, 4, 6, 7, 9, 8, 10, 5]\n",
      "3 3 [1, 3, 2, 4, 6, 7, 9, 8, 10, 5]\n",
      "4 3 [1, 2, 3, 5, 4, 7, 8, 10, 6, 9]\n",
      "4 2 [1, 2, 3, 5, 4, 7, 8, 10, 6, 9]\n",
      "1 4 [2, 6, 1, 4, 7, 3, 8, 9, 5, 10]\n",
      "1 3 [2, 6, 1, 4, 7, 3, 8, 9, 5, 10]\n",
      "3 4 [2, 6, 1, 4, 7, 3, 8, 9, 5, 10]\n",
      "3 3 [2, 6, 1, 4, 7, 3, 8, 9, 5, 10]\n",
      "4 5 [1, 6, 2, 4, 3, 5, 7, 8, 9, 10]\n",
      "4 4 [1, 6, 2, 4, 3, 5, 7, 8, 9, 10]\n",
      "4 3 [3, 1, 2, 4, 10, 7, 5, 6, 8, 9]\n",
      "4 2 [3, 1, 2, 4, 10, 7, 5, 6, 8, 9]\n",
      "3 5 [5, 1, 4, 2, 3, 6, 9, 7, 8, 10]\n",
      "3 4 [1, 4, 2, 6, 3, 9, 7, 8, 10, 5]\n",
      "3 3 [1, 4, 2, 6, 3, 9, 7, 8, 10, 5]\n",
      "4 5 [6, 1, 3, 2, 4, 5, 7, 10, 8, 9]\n",
      "4 4 [6, 1, 3, 2, 4, 5, 7, 10, 8, 9]\n",
      "4 3 [1, 2, 5, 3, 4, 7, 10, 8, 6, 9]\n",
      "4 2 [1, 2, 5, 3, 4, 7, 10, 8, 6, 9]\n",
      "3 5 [5, 2, 1, 3, 4, 6, 7, 8, 9, 10]\n",
      "3 4 [1, 3, 2, 4, 6, 8, 7, 9, 5, 10]\n",
      "3 3 [1, 3, 2, 4, 6, 8, 7, 9, 5, 10]\n",
      "4 3 [3, 1, 2, 4, 7, 8, 5, 10, 6, 9]\n",
      "4 2 [3, 1, 2, 4, 7, 8, 5, 10, 6, 9]\n",
      "[0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4]\n",
      "[0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4]\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 625 rows, 200 columns and 2200 nonzeros\n",
      "Model fingerprint: 0xc5ef1484\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Found heuristic solution: objective 16.0000000\n",
      "Presolve removed 210 rows and 10 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 415 rows, 190 columns, 2510 nonzeros\n",
      "Found heuristic solution: objective 7.0000000\n",
      "Variable types: 0 continuous, 190 integer (190 binary)\n",
      "Found heuristic solution: objective 5.0000000\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 121 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (121 simplex iterations) in 0.04 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 0 5 7 16 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[ 0  0  0  0  0]\n",
      " [ 3  2  5  1  4]\n",
      " [ 3  2  5  1  4]\n",
      " [ 8  7 10  6  9]\n",
      " [ 8  7 10  6  9]]\n",
      "the objective function 0.0\n",
      "3 4 [1, 3, 2, 4, 8, 10, 7, 5, 9, 6]\n",
      "3 3 [1, 3, 2, 4, 8, 10, 7, 5, 9, 6]\n",
      "4 4 [3, 2, 6, 5, 4, 1, 7, 9, 8, 10]\n",
      "4 3 [3, 2, 6, 5, 4, 1, 7, 9, 8, 10]\n",
      "2 4 [1, 4, 7, 5, 2, 3, 8, 6, 9, 10]\n",
      "2 3 [1, 4, 7, 5, 2, 3, 8, 6, 9, 10]\n",
      "2 4 [1, 3, 7, 4, 5, 2, 9, 6, 8, 10]\n",
      "2 3 [1, 3, 7, 4, 5, 2, 9, 6, 8, 10]\n",
      "4 4 [6, 2, 1, 3, 4, 7, 5, 10, 9, 8]\n",
      "4 3 [6, 2, 1, 3, 4, 7, 5, 10, 9, 8]\n",
      "4 4 [2, 6, 3, 4, 1, 5, 8, 7, 9, 10]\n",
      "4 3 [2, 6, 3, 4, 1, 5, 8, 7, 9, 10]\n",
      "2 4 [3, 1, 4, 6, 5, 7, 2, 9, 8, 10]\n",
      "2 3 [3, 1, 4, 6, 5, 7, 2, 9, 8, 10]\n",
      "1 4 [1, 4, 2, 5, 8, 6, 9, 7, 3, 10]\n",
      "1 3 [1, 4, 2, 5, 8, 6, 9, 7, 3, 10]\n",
      "1 4 [1, 2, 4, 8, 6, 5, 3, 7, 9, 10]\n",
      "1 3 [1, 2, 4, 8, 6, 5, 3, 7, 9, 10]\n",
      "2 4 [1, 5, 3, 7, 4, 2, 6, 9, 10, 8]\n",
      "2 3 [1, 5, 3, 7, 4, 2, 6, 9, 10, 8]\n",
      "4 4 [2, 4, 6, 5, 1, 3, 7, 10, 9, 8]\n",
      "4 3 [2, 4, 6, 5, 1, 3, 7, 10, 9, 8]\n",
      "2 4 [1, 5, 3, 6, 4, 7, 8, 2, 9, 10]\n",
      "2 3 [1, 5, 3, 6, 4, 7, 8, 2, 9, 10]\n",
      "3 4 [3, 1, 2, 4, 6, 7, 8, 9, 10, 5]\n",
      "3 3 [3, 1, 2, 4, 6, 7, 8, 9, 10, 5]\n",
      "1 4 [1, 2, 4, 8, 5, 3, 6, 9, 10, 7]\n",
      "1 3 [1, 2, 4, 8, 5, 3, 6, 9, 10, 7]\n",
      "2 4 [1, 3, 7, 4, 2, 6, 5, 8, 9, 10]\n",
      "2 3 [1, 3, 7, 4, 2, 6, 5, 8, 9, 10]\n",
      "1 4 [1, 2, 8, 4, 3, 5, 7, 6, 9, 10]\n",
      "1 3 [1, 2, 8, 4, 3, 5, 7, 6, 9, 10]\n",
      "[0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 725 rows, 200 columns and 2500 nonzeros\n",
      "Model fingerprint: 0x2eba2b25\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Found heuristic solution: objective 16.0000000\n",
      "Presolve removed 260 rows and 10 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 465 rows, 190 columns, 3100 nonzeros\n",
      "Found heuristic solution: objective 7.0000000\n",
      "Variable types: 0 continuous, 190 integer (190 binary)\n",
      "\n",
      "Root relaxation: objective 2.000000e+00, 251 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       2.0000000    2.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (251 simplex iterations) in 0.06 seconds (0.02 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 2 7 16 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "beta[ 5, 2]=1.0\n",
      "beta[ 5, 2]=1.0\n",
      "[[ 0  0  0  0  0]\n",
      " [ 3  5  2  4  1]\n",
      " [ 3  5  2  4  1]\n",
      " [ 9  6  8 10  7]\n",
      " [ 9  6  8 10  7]]\n",
      "the objective function 2.0\n",
      "2 4 [2, 1, 4, 6, 5, 3, 7, 9, 8, 10]\n",
      "2 3 [2, 1, 4, 6, 5, 3, 7, 9, 8, 10]\n",
      "2 4 [1, 2, 4, 8, 6, 5, 7, 3, 9, 10]\n",
      "2 3 [1, 2, 4, 8, 6, 5, 7, 3, 9, 10]\n",
      "2 4 [2, 1, 4, 3, 6, 5, 7, 8, 9, 10]\n",
      "2 3 [2, 1, 4, 3, 6, 5, 7, 8, 9, 10]\n",
      "2 4 [1, 2, 3, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 3 [1, 2, 3, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 4 [3, 1, 4, 2, 6, 7, 5, 9, 8, 10]\n",
      "2 3 [3, 1, 4, 2, 6, 7, 5, 9, 8, 10]\n",
      "2 4 [2, 1, 6, 4, 3, 5, 7, 9, 8, 10]\n",
      "2 3 [2, 1, 6, 4, 3, 5, 7, 9, 8, 10]\n",
      "2 4 [1, 2, 3, 4, 6, 5, 8, 7, 10, 9]\n",
      "2 3 [1, 2, 3, 4, 6, 5, 8, 7, 10, 9]\n",
      "2 4 [1, 3, 2, 4, 6, 7, 5, 8, 9, 10]\n",
      "2 3 [1, 3, 2, 4, 6, 7, 5, 8, 9, 10]\n",
      "2 4 [1, 3, 2, 4, 6, 5, 8, 7, 10, 9]\n",
      "2 3 [1, 3, 2, 4, 6, 5, 8, 7, 10, 9]\n",
      "2 4 [3, 2, 4, 1, 6, 7, 5, 8, 9, 10]\n",
      "2 3 [3, 2, 4, 1, 6, 7, 5, 8, 9, 10]\n",
      "2 4 [1, 2, 3, 4, 6, 5, 7, 8, 9, 10]\n",
      "2 3 [1, 2, 3, 4, 6, 5, 7, 8, 9, 10]\n",
      "2 4 [1, 3, 4, 2, 6, 5, 7, 9, 8, 10]\n",
      "2 3 [1, 3, 4, 2, 6, 5, 7, 9, 8, 10]\n",
      "2 4 [1, 2, 4, 6, 5, 3, 8, 7, 9, 10]\n",
      "2 3 [1, 2, 4, 6, 5, 3, 8, 7, 9, 10]\n",
      "2 4 [2, 1, 4, 3, 7, 6, 5, 10, 8, 9]\n",
      "2 3 [2, 1, 4, 3, 7, 6, 5, 10, 8, 9]\n",
      "2 4 [1, 3, 4, 2, 7, 6, 5, 8, 10, 9]\n",
      "2 3 [1, 3, 4, 2, 7, 6, 5, 8, 10, 9]\n",
      "2 4 [1, 2, 3, 6, 4, 5, 7, 8, 9, 10]\n",
      "2 3 [1, 2, 3, 6, 4, 5, 7, 8, 9, 10]\n",
      "2 4 [1, 2, 4, 3, 6, 7, 5, 8, 10, 9]\n",
      "2 3 [1, 2, 4, 3, 6, 7, 5, 8, 10, 9]\n",
      "2 4 [1, 2, 3, 6, 5, 4, 7, 8, 9, 10]\n",
      "2 3 [1, 2, 3, 6, 5, 4, 7, 8, 9, 10]\n",
      "2 4 [2, 1, 3, 6, 5, 4, 8, 9, 7, 10]\n",
      "2 3 [2, 1, 3, 6, 5, 4, 8, 9, 7, 10]\n",
      "2 4 [2, 1, 4, 6, 3, 5, 7, 8, 9, 10]\n",
      "2 3 [2, 1, 4, 6, 3, 5, 7, 8, 9, 10]\n",
      "2 4 [1, 3, 2, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 3 [1, 3, 2, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 4 [1, 2, 3, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 3 [1, 2, 3, 4, 6, 5, 8, 7, 9, 10]\n",
      "2 4 [1, 3, 2, 6, 5, 4, 7, 9, 8, 10]\n",
      "2 3 [1, 3, 2, 6, 5, 4, 7, 9, 8, 10]\n",
      "2 4 [1, 2, 3, 6, 5, 4, 7, 8, 10, 9]\n",
      "2 3 [1, 2, 3, 6, 5, 4, 7, 8, 10, 9]\n",
      "2 4 [1, 2, 4, 3, 6, 5, 8, 7, 9, 10]\n",
      "2 3 [1, 2, 4, 3, 6, 5, 8, 7, 9, 10]\n",
      "2 4 [1, 2, 3, 4, 6, 7, 5, 9, 8, 10]\n",
      "2 3 [1, 2, 3, 4, 6, 7, 5, 9, 8, 10]\n",
      "2 4 [1, 4, 3, 2, 6, 5, 9, 7, 10, 8]\n",
      "2 3 [1, 4, 3, 2, 6, 5, 9, 7, 10, 8]\n",
      "2 4 [1, 2, 3, 4, 6, 5, 8, 9, 7, 10]\n",
      "2 3 [1, 2, 3, 4, 6, 5, 8, 9, 7, 10]\n",
      "2 4 [1, 3, 2, 4, 6, 7, 5, 8, 9, 10]\n",
      "2 3 [1, 3, 2, 4, 6, 7, 5, 8, 9, 10]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=(tuple(pcvar),)\n",
    "l=[\"75%-CVaR\"]\n",
    "for g in range(1,6):\n",
    "  prob=[]\n",
    "  for i in inst:\n",
    "    ship_num=len(i[2])\n",
    "    robust(ship_num,i[0],i[1],i[2],g,size,var)\n",
    "    prob+=list(penalty_r)\n",
    "    print(prob)\n",
    "  data+=(tuple(prob),)\n",
    "  l.append(\"Gamma=\"+str(g))\n",
    "  # print(\"data=\",data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(data,labels=l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6), (6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 10), (3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7), (3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 6, 7, 8), (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4), (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6))\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bc652a6662848c169ddaad7e75fc7966486f1f662e7670e7ffb2b305ef6abae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
