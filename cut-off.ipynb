{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本研究"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVaR(ship_num,stack_num,height,n_init,size,size_,beta,mean,cov,OC): \n",
    "  O1=[i+1 for i in range(ship_num)]\n",
    "  S=[i+1 for i in range(stack_num)]\n",
    "  H=[i+1 for i in range(height)]\n",
    "  P=[i+1 for i in range(ship_num)]\n",
    "  f=stack_num*height-sum(n_init)\n",
    "\n",
    "  from asyncio.constants import SENDFILE_FALLBACK_READBUFFER_SIZE\n",
    "  import random\n",
    "  from random import seed\n",
    "  import numpy as np\n",
    "  from scipy.stats import multivariate_normal\n",
    "\n",
    "  # 期待値と分散共分散行列の準備\n",
    "  data_1 = np.random.multivariate_normal(mean, cov, size=size)\n",
    "\n",
    "  O_=np.argsort(data_1)\n",
    "  O_=O_+np.ones((size,ship_num)).astype(int)\n",
    "  global O\n",
    "  O=O_.tolist()\n",
    "  m=Model(\"CVaR\")\n",
    "\n",
    "  alpha=m.addVar(vtype=\"C\")\n",
    "\n",
    "  # 変数の定義\n",
    "  x,c,d={},{},{}\n",
    "  for s in S:\n",
    "    for h in H:\n",
    "      for p in P:\n",
    "        x[s,h,p]=m.addVar(vtype=\"B\")\n",
    "\n",
    "  for s in S:\n",
    "    for h in range(2,len(H)+1):\n",
    "      for i,o in enumerate(O):\n",
    "        c[s,h,i]=m.addVar(vtype=\"c\",lb=0)\n",
    "\n",
    "  for i in range(len(O)):\n",
    "    d[i]=m.addVar(vtype=\"C\",lb=0)\n",
    "\n",
    "  for p in P:\n",
    "    m.addConstr(quicksum(x[s,h,p] for s in S for h in H)==n_init[p-1])\n",
    "\n",
    "  for s in S:\n",
    "    for h in H:\n",
    "      m.addConstr(quicksum(x[s,h,p] for p in P)<=1)\n",
    "\n",
    "  for s in S:\n",
    "    for h in range(1,len(H)):\n",
    "      m.addConstr(quicksum(x[s,h+1,p] for p in P)<=quicksum(x[s,h,p] for p in P))\n",
    "\n",
    "  for s in S:\n",
    "    for h in range(2,len(H)+1):\n",
    "      for h_ in range(1,h):\n",
    "        for i,o in enumerate(OC):\n",
    "          for j,p in enumerate(o):\n",
    "            m.addConstr(c[s,h,i]>=quicksum(x[s,h,k] for k in o[j:])-quicksum(x[s,h_,k] for k in o[j:]))\n",
    "\n",
    "  for i in range(len(OC)):\n",
    "    m.addConstr(d[i]>=quicksum(c[s,h,i] for s in S for h in H if h!=1)-alpha)\n",
    "\n",
    "\n",
    "  m.setObjective(alpha+quicksum(d[i] for i in range(len(O)))/((1-beta)*len(O)))\n",
    "\n",
    "  if f>=height:\n",
    "    m.optimize()\n",
    "  else:\n",
    "    print(\"f<h\")\n",
    "  # m.optimize()\n",
    "\n",
    "  print(\"================================================\")\n",
    "\n",
    "  EPS=1.e-6\n",
    "\n",
    "  if m.Status == GRB.OPTIMAL:\n",
    "\n",
    "    global result\n",
    "    result=np.zeros((height,stack_num))\n",
    "    for (s,h,p) in x:\n",
    "      if x[s,h,p].X>EPS:\n",
    "        result[height-h][s-1]=int(p)\n",
    "\n",
    "    result=result.astype(int)\n",
    "    # print(\"VaR=\",alpha.X)\n",
    "    # print(\"the objective function\", m.objVal)\n",
    "    global LB\n",
    "    LB=m.objVal\n",
    "    # print(result)\n",
    "\n",
    "    global penalty\n",
    "    penalty=[]\n",
    "    for k in O:\n",
    "      OO=k\n",
    "      a=0\n",
    "      for j in range(stack_num):\n",
    "          for i in range(1,height):\n",
    "              for i_ in range(i+1,height+1):\n",
    "                  if result[i-1][j]!=0 and result[i_-1][j]!=0:\n",
    "                      if OO.index(result[i-1][j])>OO.index(result[i_-1][j]):\n",
    "                          # print(j+1,height-i+1,O)\n",
    "                          a+=1\n",
    "                          # print(\"penalty!\")\n",
    "                              # print(i,i_,j+1,O)\n",
    "                          break\n",
    "      penalty.append(a)\n",
    "      # print(a)\n",
    "    penalty=np.sort(penalty)\n",
    "    # print(penalty)\n",
    "\n",
    "    # penalty=penalty[round(0.75*size):]\n",
    "    # print(penalty)\n",
    "\n",
    "def robust(ship_num,stack_num,height,n,Gamma,size_,mean,cov):\n",
    "  # nと初期配置を変更しなければいけない\n",
    "  num=sum(n)\n",
    "\n",
    "  import numpy as np\n",
    "\n",
    "  O1=[i+1 for i in range(ship_num)]\n",
    "\n",
    "  Q=[i+1 for i in range(stack_num)]\n",
    "  L=[i+1 for i in range(height)]\n",
    "  P=[i+1 for i in range(ship_num)]\n",
    "  I=[i+1 for i in range(num)]\n",
    "  f=stack_num*height-len(I)\n",
    "  a=1\n",
    "  gamma=[]\n",
    "  for i in n:\n",
    "      for j in range(1,i+1):\n",
    "          gamma.append(a)\n",
    "      a+=1\n",
    "  \n",
    "  m=Model(\"BI\")\n",
    "\n",
    "  # 変数の定義\n",
    "  alpha,beta={},{}\n",
    "  for i in I:\n",
    "      for q in Q:\n",
    "          alpha[i,q]=m.addVar(vtype=\"B\")\n",
    "          beta[i,q]=m.addVar(vtype=\"B\")\n",
    "  J=[]\n",
    "  for i in I:\n",
    "      J.append([])\n",
    "      for j in I:\n",
    "          if gamma[i-1]<gamma[j-1]:\n",
    "              if gamma[j-1]-gamma[i-1]<=Gamma:\n",
    "                  J[i-1].append(j)\n",
    "\n",
    "  for q in Q:\n",
    "      m.addConstr(quicksum((alpha[i,q]+beta[i,q]) for i in I)<=len(L))\n",
    "\n",
    "  for i in I:\n",
    "      m.addConstr(quicksum((alpha[i,q]+beta[i,q]) for q in Q)==1)\n",
    "\n",
    "  for i in I:\n",
    "      for j in J[i-1]:\n",
    "          for q in Q:\n",
    "              m.addConstr(alpha[i,q]+alpha[j,q]+beta[j,q]<=1)\n",
    "\n",
    "  m.setObjective(quicksum(beta[i,q] for i in I for q in Q))\n",
    "\n",
    "  if f>=height:\n",
    "      m.optimize()\n",
    "\n",
    "  EPS=1.e-6\n",
    "\n",
    "  if m.Status == GRB.OPTIMAL:\n",
    "      print(\"====================================================\")\n",
    "\n",
    "      EPS=1.e-6\n",
    "      a=[]\n",
    "      for q in Q:\n",
    "          a.append([])\n",
    "      for (i,q) in alpha:\n",
    "          if alpha[i,q].X>EPS:\n",
    "              a[q-1].append(gamma[i-1])\n",
    "      \n",
    "      for (i,q) in beta:\n",
    "          if beta[i,q].X>EPS:\n",
    "              a[q-1].append(gamma[i-1])\n",
    "\n",
    "      for q in Q:\n",
    "          a[q-1]=sorted(a[q-1],reverse=True)\n",
    "\n",
    "      global result_r\n",
    "      result_r=np.zeros((height,stack_num))\n",
    "      for q in Q:\n",
    "          for i,r in enumerate(a[q-1]):\n",
    "              result_r[height-i-1][q-1]=r\n",
    "          # print(i,r)\n",
    "\n",
    "      result_r=result_r.astype(int)\n",
    "      \n",
    "      print(result_r)\n",
    "      print(\"the objective function\", m.objVal)\n",
    "\n",
    "      from asyncio.constants import SENDFILE_FALLBACK_READBUFFER_SIZE\n",
    "      import random\n",
    "      from random import seed\n",
    "      import numpy as np\n",
    "      from scipy.stats import multivariate_normal\n",
    "\n",
    "      np.random.seed()\n",
    "      data_1 = np.random.multivariate_normal(mean, cov, size=size_)\n",
    "\n",
    "      O_=np.argsort(data_1)\n",
    "      O_=O_+np.ones((size_,ship_num)).astype(int)\n",
    "      OR=O_.tolist()\n",
    "\n",
    "\n",
    "      global penalty_r\n",
    "      penalty_r=[]\n",
    "      for k in OR:\n",
    "          O=k\n",
    "          a=0\n",
    "          for j in range(stack_num):\n",
    "              for i in range(1,height):\n",
    "                  for i_ in range(i+1,height+1):\n",
    "                      if result_r[i-1][j]!=0 and result_r[i_-1][j]!=0:\n",
    "                          if O.index(result_r[i-1][j])>O.index(result_r[i_-1][j]):\n",
    "                              a+=1\n",
    "                              # if Gamma ==2:\n",
    "                                # print(j+1,height-i+1,O)\n",
    "                              # print(\"penalty!\")\n",
    "                              # print(i,i_,j+1,O)\n",
    "                              break\n",
    "          penalty_r.append(a)\n",
    "      \n",
    "      penalty_r=np.sort(penalty_r)\n",
    "      penalty_r=penalty_r[round(0.75*size_):]\n",
    "      # print(penalty_r)\n",
    "\n",
    "      # import matplotlib.pyplot as plt\n",
    "      # plt.boxplot(penalty_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 54 rows, 63226 columns and 810 nonzeros\n",
      "Model fingerprint: 0x70cf9da4\n",
      "Variable types: 63001 continuous, 225 integer (225 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e-03, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+00]\n",
      "Found heuristic solution: objective 0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.03 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "================================================\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 135354 rows, 63226 columns and 1492410 nonzeros\n",
      "Model fingerprint: 0xbdc803a3\n",
      "Variable types: 63001 continuous, 225 integer (225 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e-03, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+00]\n",
      "Presolve removed 300 rows and 57001 columns (presolve time = 5s) ...\n",
      "Presolve removed 23250 rows and 58021 columns (presolve time = 10s) ...\n",
      "Presolve removed 23250 rows and 58021 columns\n",
      "Presolve time: 10.20s\n",
      "Presolved: 112104 rows, 5205 columns, 1233360 nonzeros\n",
      "Variable types: 4980 continuous, 225 integer (225 binary)\n",
      "Found heuristic solution: objective 3.8840000\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0      handle free variables                         14s\n",
      "    1142   -0.0000000e+00   0.000000e+00   0.000000e+00     15s\n",
      "    1142   -0.0000000e+00   0.000000e+00   0.000000e+00     15s\n",
      "    1142    0.0000000e+00   0.000000e+00   0.000000e+00     15s\n",
      "\n",
      "Use crossover to convert LP symmetric solution to basic solution...\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "     133 PPushes remaining with PInf 0.0000000e+00                15s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00                15s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 0.0000000e+00     15s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    1278    0.0000000e+00   0.000000e+00   0.000000e+00     16s\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 1278 iterations, 3.16 seconds (1.14 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   24    3.88400    0.00000   100%     -   19s\n",
      "H    0     0                       0.8453333    0.00000   100%     -   20s\n",
      "     0     0    0.00000    0   39    0.84533    0.00000   100%     -   24s\n",
      "H    0     0                       0.8400000    0.00000   100%     -   26s\n",
      "     0     0    0.00000    0   31    0.84000    0.00000   100%     -   30s\n",
      "     0     0    0.00000    0   23    0.84000    0.00000   100%     -   36s\n",
      "H    0     0                       0.8226667    0.00000   100%     -   37s\n",
      "H    0     0                       0.7093333    0.00000   100%     -   37s\n",
      "     0     0    0.00000    0   31    0.70933    0.00000   100%     -   44s\n",
      "H    0     0                       0.3573333    0.00000   100%     -   46s\n",
      "     0     0    0.00000    0   30    0.35733    0.00000   100%     -   46s\n",
      "     0     0    0.00000    0   35    0.35733    0.00000   100%     -   51s\n",
      "     0     0    0.00000    0   33    0.35733    0.00000   100%     -   61s\n",
      "     0     0    0.00000    0   33    0.35733    0.00000   100%     -   64s\n",
      "     0     2    0.00000    0   28    0.35733    0.00000   100%     -   82s\n",
      "     1     4    0.00000    1   47    0.35733    0.00000   100%   435   86s\n",
      "     3     8    0.00000    2   45    0.35733    0.00000   100%   414   93s\n",
      "     7     8    0.00267    3   60    0.35733    0.00000   100%   581  103s\n",
      "    11    12    0.00053    3   33    0.35733    0.00053   100%   525  109s\n",
      "    15    16    0.00387    4   66    0.35733    0.00053   100%   567  114s\n",
      "    19    18    0.00213    4   31    0.35733    0.00213  99.4%   529  126s\n",
      "    23    23    0.00427    5   32    0.35733    0.00213  99.4%   605  132s\n",
      "    28    27    0.08147    5   28    0.35733    0.00267  99.3%   570  139s\n",
      "H   31    27                       0.2133333    0.00267  98.7%   540  139s\n",
      "    32    28    0.12467    6   32    0.21333    0.00267  98.7%   551  152s\n",
      "    37    30    0.01067    6   17    0.21333    0.00267  98.7%   587  162s\n",
      "    43    35    0.11467    7   28    0.21333    0.00267  98.7%   652  183s\n",
      "*   47    35               9       0.0213333    0.00267  87.5%   690  183s\n",
      "    50    32     cutoff    8         0.02133    0.00267  87.5%   668  190s\n",
      "    61    38     cutoff   10         0.02133    0.00302  85.8%   589  205s\n",
      "    75    30     cutoff    5         0.02133    0.00387  81.9%   549  218s\n",
      "*   81    30              13       0.0186667    0.00387  79.3%   529  218s\n",
      "    89    29     cutoff    6         0.01867    0.00387  79.3%   526  227s\n",
      "    98    30    0.01053    7   45    0.01867    0.00387  79.3%   502  281s\n",
      "   103    31     cutoff    8         0.01867    0.00387  79.3%   567  299s\n",
      "   112    27    0.01187    9   42    0.01867    0.00387  79.3%   595  308s\n",
      "   126    22    0.01187   10   33    0.01867    0.00387  79.3%   556  332s\n",
      "   137     9    0.01440   10   26    0.01867    0.01027  45.0%   565  375s\n",
      "   158     5     cutoff    6         0.01867    0.01342  28.1%   570  389s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 6\n",
      "  RLT: 20\n",
      "\n",
      "Explored 169 nodes (99945 simplex iterations) in 389.88 seconds (459.98 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 9: 0.0186667 0.0213333 0.213333 ... 3.884\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.866666666667e-02, best bound 1.866666666667e-02, gap 0.0000%\n",
      "================================================\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 270654 rows, 63226 columns and 2984010 nonzeros\n",
      "Model fingerprint: 0xe07a577e\n",
      "Variable types: 63001 continuous, 225 integer (225 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e-03, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+00]\n",
      "Presolve removed 600 rows and 51001 columns (presolve time = 5s) ...\n",
      "Presolve removed 600 rows and 51001 columns (presolve time = 10s) ...\n",
      "Presolve removed 77100 rows and 54401 columns (presolve time = 16s) ...\n",
      "Presolve removed 77100 rows and 54401 columns (presolve time = 21s) ...\n",
      "Presolve removed 77100 rows and 54401 columns\n",
      "Presolve time: 23.82s\n",
      "Presolved: 193554 rows, 8825 columns, 2129310 nonzeros\n",
      "Variable types: 8600 continuous, 225 integer (225 binary)\n",
      "Found heuristic solution: objective 7.8253333\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0      handle free variables                         30s\n",
      "     467    3.2000000e+29   8.840000e+31   4.096000e+01     30s\n",
      "    1008   -0.0000000e+00   0.000000e+00   0.000000e+00     30s\n",
      "    1008   -0.0000000e+00   0.000000e+00   0.000000e+00     30s\n",
      "    1008    0.0000000e+00   0.000000e+00   0.000000e+00     31s\n",
      "\n",
      "Use crossover to convert LP symmetric solution to basic solution...\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "       7 DPushes remaining with DInf 0.0000000e+00                31s\n",
      "\n",
      "     154 PPushes remaining with PInf 0.0000000e+00                31s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00                32s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 0.0000000e+00     32s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    1165    0.0000000e+00   0.000000e+00   0.000000e+00     32s\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 1165 iterations, 4.85 seconds (2.10 work units)\n",
      "Total elapsed time = 36.07s\n",
      "Total elapsed time = 40.71s\n",
      "Total elapsed time = 45.08s\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   37    7.82533    0.00000   100%     -   47s\n",
      "H    0     0                       3.2066667    0.00000   100%     -   49s\n",
      "     0     0    0.00000    0   42    3.20667    0.00000   100%     -   63s\n",
      "H    0     0                       3.0173333    0.00000   100%     -   68s\n",
      "     0     0    0.00000    0   30    3.01733    0.00000   100%     -   89s\n",
      "     0     0    0.00000    0   41    3.01733    0.00000   100%     -  103s\n",
      "H    0     0                       2.7106667    0.00000   100%     -  105s\n",
      "     0     0    0.00000    0   47    2.71067    0.00000   100%     -  119s\n",
      "H    0     0                       1.5333333    0.00000   100%     -  122s\n",
      "     0     0    0.00000    0   31    1.53333    0.00000   100%     -  141s\n",
      "     0     0    0.00000    0   39    1.53333    0.00000   100%     -  148s\n",
      "     0     0    0.00000    0   24    1.53333    0.00000   100%     -  163s\n",
      "H    0     0                       1.5226667    0.00000   100%     -  166s\n",
      "     0     0    0.00000    0   39    1.52267    0.00000   100%     -  179s\n",
      "H    0     0                       1.2480000    0.00000   100%     -  181s\n",
      "     0     0    0.00000    0   38    1.24800    0.00000   100%     -  192s\n",
      "     0     0    0.00000    0   38    1.24800    0.00000   100%     -  197s\n",
      "H    0     0                       0.6293333    0.00000   100%     -  214s\n",
      "     0     2    0.00000    0   38    0.62933    0.00000   100%     -  237s\n",
      "     1     4    0.00000    1   58    0.62933    0.00000   100%   760  241s\n",
      "     3     8    0.00090    2   84    0.62933    0.00000   100%   791  262s\n",
      "     7    12    0.00267    3   50    0.62933    0.00000   100%   503  276s\n",
      "    11    16    0.02947    4   59    0.62933    0.00000   100%  1259  370s\n",
      "    15    20    0.15800    4   56    0.62933    0.00090   100%  1056  384s\n"
     ]
    }
   ],
   "source": [
    "size=3000\n",
    "size_=10000\n",
    "beta=0.75\n",
    "inst=[5,5,[2,2,2,2,2,2,2,2,2]]\n",
    "pcvar=[]\n",
    "import numpy as np\n",
    "# mean=np.arange(1,ship_num+1)\n",
    "mean=np.array([0.8,1,3,3.2,3.5,5.5,6,7.8,8])\n",
    "covl=[2 for i in range(len(inst[2]))]\n",
    "# a=list(a)\n",
    "# a=random.sample(a,ship_num)\n",
    "# mean=np.sort(a)\n",
    "cov=np.zeros((len(inst[2]),len(inst[2])))\n",
    "for i in range(len(inst[2])):\n",
    "    for j in range(len(inst[2])):\n",
    "        if i==j:\n",
    "            cov[i][i]=covl[1]\n",
    "for i in range(len(inst[2])):\n",
    "    for j in range(len(inst[2])):\n",
    "        if i!=j:\n",
    "            cov[i][j]=0\n",
    "OC=[]\n",
    "EPS=0.1\n",
    "a=0\n",
    "UB=1000\n",
    "LB=0\n",
    "UB_k=[]\n",
    "while UB-LB>=EPS and a<10:\n",
    "    CVaR(len(inst[2]),inst[0],inst[1],inst[2],size,size_,beta,mean,cov,OC)\n",
    "    n=0\n",
    "    while n<beta*size:\n",
    "        n+=1\n",
    "    tau=n\n",
    "    alpha_=penalty[tau-1]\n",
    "\n",
    "    UB=((tau/size-beta)*alpha_+sum(penalty[tau:]))\n",
    "    UB_k.append(UB)\n",
    "    UB=min(UB_k)\n",
    "    for b in range(round(size*0.1*a),round(size*0.1*(a+1))):\n",
    "        OC.append(O[b])\n",
    "    a+=1\n",
    "    # print(OC)\n",
    "print(\"finish!!\")\n",
    "\n",
    "data_2 = np.random.multivariate_normal(mean, cov, size=size_)\n",
    "\n",
    "OR_=np.argsort(data_2)\n",
    "OR_=OR_+np.ones((size_,len(inst[2]))).astype(int)\n",
    "OR=OR_.tolist()\n",
    "penalty_cvar=[]\n",
    "for k in OR:\n",
    "    OR2=k\n",
    "    a=0\n",
    "    for j in range(inst[0]):\n",
    "        for i in range(1,inst[1]):\n",
    "            for i_ in range(i+1,inst[1]+1):\n",
    "                if result[i-1][j]!=0 and result[i_-1][j]!=0:\n",
    "                    if OR2.index(result[i-1][j])>OR2.index(result[i_-1][j]):\n",
    "                        # print(j+1,height-i+1,O)\n",
    "                        a+=1\n",
    "                        # print(\"penalty!\")\n",
    "                            # print(i,i_,j+1,O)\n",
    "                        break\n",
    "    penalty_cvar.append(a)\n",
    "penalty_cvar=np.sort(penalty_cvar)\n",
    "penalty_cvar=penalty_cvar[round(0.75*size_):]\n",
    "pcvar=[]\n",
    "pcvar+=list(penalty_cvar)\n",
    "data=(tuple(pcvar),)\n",
    "l=[\"75%-CVaR\"]\n",
    "for g in range(1,6):\n",
    "  prob=[]\n",
    "  ship_num=len(inst[2])\n",
    "  robust(ship_num,inst[0],inst[1],inst[2],g,size_,mean,cov)\n",
    "  prob+=list(penalty_r)\n",
    "#   print(prob)\n",
    "  data+=(tuple(prob),)\n",
    "  l.append(\"Gamma=\"+str(g))\n",
    "  # print(\"data=\",data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(data,labels=l)\n",
    "plt.show()\n",
    "# plt.hist(penalty_cvar,bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 96 rows, 96 columns and 432 nonzeros\n",
      "Model fingerprint: 0x7653d5fb\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 4.0000000\n",
      "Presolve removed 0 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 96 rows, 88 columns, 400 nonzeros\n",
      "Found heuristic solution: objective 0.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 0 4 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[1 0 0 1]\n",
      " [3 0 0 4]\n",
      " [3 2 2 4]\n",
      " [5 5 6 6]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 160 rows, 96 columns and 624 nonzeros\n",
      "Model fingerprint: 0x14f73017\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 4.0000000\n",
      "Presolve removed 48 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 112 rows, 88 columns, 528 nonzeros\n",
      "Found heuristic solution: objective 3.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 24 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (24 simplex iterations) in 0.03 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0 3 4 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[3 1 0 0]\n",
      " [3 1 2 0]\n",
      " [6 4 5 0]\n",
      " [6 4 5 2]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 208 rows, 96 columns and 768 nonzeros\n",
      "Model fingerprint: 0x80e74690\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 6.0000000\n",
      "Presolve removed 80 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 128 rows, 88 columns, 656 nonzeros\n",
      "Found heuristic solution: objective 2.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 40 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (40 simplex iterations) in 0.04 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0 2 6 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 2 1 0]\n",
      " [0 2 1 0]\n",
      " [3 6 5 4]\n",
      " [3 6 5 4]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 240 rows, 96 columns and 864 nonzeros\n",
      "Model fingerprint: 0x4c425b2c\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 6.0000000\n",
      "Presolve removed 72 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 168 rows, 88 columns, 920 nonzeros\n",
      "Found heuristic solution: objective 2.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: cutoff, 102 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0         2.00000    2.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (102 simplex iterations) in 0.04 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 2 6 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 0 0 1]\n",
      " [2 2 0 1]\n",
      " [5 3 4 6]\n",
      " [5 3 4 6]]\n",
      "the objective function 2.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 256 rows, 96 columns and 912 nonzeros\n",
      "Model fingerprint: 0x4c9c2536\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 5.0000000\n",
      "Presolve removed 80 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 176 rows, 88 columns, 1008 nonzeros\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "Found heuristic solution: objective 4.0000000\n",
      "\n",
      "Root relaxation: cutoff, 82 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0         4.00000    4.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (82 simplex iterations) in 0.05 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 4 5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.000000000000e+00, best bound 4.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 2 0 0]\n",
      " [1 2 0 1]\n",
      " [5 3 4 6]\n",
      " [5 3 4 6]]\n",
      "the objective function 4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACGgAAAFgCAYAAADt+909AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABE80lEQVR4nO39f7ylZ1kf+n8uM4A/AANmSmMSnEhDegAxwBRSrYgGMIBfgj0emtRKQGpKCVWL52iw5xSrpSe2WpCD4AkQE3ogAQFLKkFI8Qf1HAIMEEPCjzKEYCYNZCD8UMFg4Pr+sZ4hK5O99+yZvZ+1nj37/X691muedT/3eta11qx1rXvuuZ77qe4OAAAAAAAAAADj+aZlBwAAAAAAAAAAcLRToAEAAAAAAAAAMDIFGgAAAAAAAAAAI1OgAQAAAAAAAAAwMgUaAAAAAAAAAAAjU6ABAAAAAAAAADAyBRoAAAAAAAAAACNToMFkVdVfHnT7WlX9X8O+XVXVB+3/P+Ye+79V1Wer6vqq+p659u+vqv+8jueuqvqZqrquqv6qqvZV1e9W1fdU1QVV9a4VHnNcVX21qh52iGP/cVX99RDzZ6vqzVV1/GG9OQBLUFVnV9V7hrx467D93KqqZce2Garqoqr6WFV9vaqeuex4AA7laM7LVfXgqnpLVe2vqtuq6u1Vdeqy4wI4lKM8Nx9XVf9vVX2uqr5QVe+uqu9fdlwAazma8/K8qnrGMF/+T5cdC8Bajva8POTiv5r7v8tXLTsmpkeBBpPV3fc+cEvyt5N8JcnvHtTt2Ll+v5okQ7HDs5N8d5JXJPk/h/YdSX4jyc+t4+l/M8nPJvmZJPdP8uAk/znJU5L8P0m+r6pOPugxZyf5UHdft47jP294XX8nyb2T/Po6HgOwNFX185nlxv+QWU5+QJLnJPn+JPdcYmib6c+SPDfJB5YdCMChbIO8fGySK5Kcmtlre2+StywzIIBD2Qa5+S+T/FSSnUnul+TXkvyXYb4FYHK2QV5OklTV/ZL8UpLrlx0LwFq2S15O8r1z/3epcI67UaDBVvE/J7k1yX9bR98HJvlgd38pyX/NrFAjmRVmXNHdN6714Ko6Jcn5Sc7p7j/s7tu7+8vd/druvrC79yX5wyQ/edBDn5HkNVV1v6r6/eFsv88P2yeu9Fzd/YXMCj9OW8frAliKqvr2JL+S5Lnd/cbu/oue+WB3/0R3315VT6mqD1bVl6rqpqr65bnHH1j16FnDvs9X1XOq6u9V1bXD2Xcvm+v/zOHMvBcP+26oqu8b2m8aKqvPneu/6nMfju7+re5+Z5K/PuI3C2ABtkNe7u73dveru/u27v6bJC9OcmpVfcdG3juAsWyT3PzX3f2x7v56kkrytcwKNe5/5O8cwDi2Q16e838meWmSz27gGACj2mZ5GdakQIOt4twkr+nuPqj9UzW7/MjvVNVxQ9veJN9TVccmeXyS66vqpMxWuFjPShVnJNnX3e9do8+lmSvQqNlyy6cleV1m36vfSfJdmRWLfCXJy+5+iGSYYP6HQ8wAU/X3k9wra5+5/FeZFaodm9lqQ/+8qp52UJ/HJDklyT9K8pIk/yqzPP3QJE+vqh88qO+1Sb4js9x6eZK/l9nKQ/8kycuq6t7ree5hAL7a7YL1vw0Ak7Ed8/Jjk3y6uz+3xmsGWKZtk5ur6trMipqvSPKq7r51zXcGYDm2RV6uqkcn2Z3ktw/9lgAs1bbIy4N3VdWnq+rNVbVrrTeF7UmBBpNXVd+V5AczK4o44LOZJdHvSvKoJPdJ8tokGSZtX5TZKhdPSfK/ZrZk0i8m+bGq+pOaXc96xVUtMkvUtxwirN9L8oCq+r7h/jOSvK2793f357r7TcOqG38xxPKDBz3+pVX1xeF1HJfkXxzi+QCW6bgkn+3uOw40VNX/Nww+v1JVj+3uP+7uD3X317v72iSX5e6571eHs+7ekdmA97LuvrW7b85shaRHzPX9ZHf/Tnd/Lcnrk5yU5FeGVY3ekeSrmQ2kc6jn7u5j17hduNlvFsACbKu8PIzbfyvJ8zf6xgGMaNvk5u5+eJL7JvnHSf50E947gDEc9Xm5qo5J8vLMLqf99c188wBGcNTn5cEPJtmV5O8m+R9Jfr9cEpCDKNBgK/jJJH/a3Z880NDdf9nde7r7ju7+TJLnJXliVd1n2H9Zdz+yu5+U5GFJbk/ywcxW0Pj/JfndYTtVdX1V/eVw+4Ekn0ty/FoBdfeXh2M8o6oqyU8kec1wvG+tqv+7qj5VVV9K8q4kxw4D5gN+pru/PcnDM1sOdLViEYAp+FyS4+YHkt39fd197LDvm6rqMVX1RzW7vNMXM7t24HEHHeczc9tfWeH+vdfomyHf363/Op8b4GiybfJyVe1M8o4kL+/uy47kGAALsm1y8/A8fz3k5Quq6nuP9DgAI9oOefm5Sa7t7qsP83EAy7Ad8nK6+13d/dXu/kKSn01ycpL/6XCPw9FNgQZbwTNy19UzVnLg0id3+UxX1bck+XdJfj6zJY9u6u4vJXlfZsUR6e6Hdve9h9t/S/LOJCdW1e5DPOelSZ6e5AmZreDxX4b2n09yapLHdPd9M1uOOZldn/WuQXd/KMm/TfJbQ6EHwBS9O7NCt7PW6PO6zJY4PmkoQPvtrJD3RrLmc88V4a10+6UFxQiwmbZFXq6q+2VWnHFFd79oQbEDHKltkZtXcI8k3z1u6ABHZDvk5TMyWzH601X16STfl+Q3qmrFy20DLNl2yMsr6SzuNbBFWFKFSavZJUROyGy1ivn2xyT5QpKPZ7YCxUuT/HF3f/GgQ/zvSS7p7v9RVZ3k1Kp6QJIfSnLDSs/Z3R+vqpcnuayqfjrJ/5dZ4cfTkuyaW6rovw0xXJTk8u7+6tB+n8yq7r5QVfdP8sJDvMxLk/ybJE/N2tfeAliK7v5CVf2bJC8fisnentnycQ9P8m1Dt/skua27/7pm1z/9x5n9p9oirPnc3X3vVR85p6rumVm+ryT3qKpvTvJVy4QCU7Md8nJV3Tez1/X/dvfB13IFmJxtkptPz2wu8b1JjknyM0kekOQ9o0QMsAHbIS8neWaSb567/+Ykb0zy6k2ME2BTbIe8XFUPzayA+UNJviWzE7RvTvKRUSJmy7KCBlN3bpI3d/dfHNT+3Un+IMlfJLkus6q7c+Y7VNXfTfLEzIo30t23JLkwyfWZTSK8YI3n/ZkkL8vsWtdfSPKJJD+WO1fJSHd3Zpc1+a7hzwNeklni/WySq4c4VzUUdvxmkv9jrX4Ay9Td/z7J85P8QmZLw30myf+d5BczK2R7bpJfqaq/SPKvk7xhgeFt1nO/I7MCu+/LrPjuK7lzFSSASdkGefnHkvy9JM866KyUB25moACbaRvk5ntlNk/yucwmmp+c5Cnd/T82LUqATXS05+Xu/kJ3f/rALclXk3xphZMYASbhaM/LmRUvvz7JlzI7SXxXkh/t7r/ZrCA5OtTs/5gBAAAAAAAAABiLFTQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAAAAARqZAAwAAAAAAAABgZDuWHcBajjvuuN61a9eywwAY1fvf//7PdvfOw3lMVV2c5EeT3NrdD5tr/xdJzk/ytSRv7e5fGNpfkOTZQ/vPdPfbh/Yzk/xmkmOSvKq7LzzUc8vNwHZwJLl5WeRlYDuQlwGmRV4GmJatlJcTuRnYHlbLzZMu0Ni1a1f27Nmz7DAARlVVnzqCh12S5GVJXjN3nB9KclaS7+3u26vqbw3tD0lydpKHJvnOJP+1qh48POy3kjwhyb4k76uqK7r7w2s9sdwMbAdHmJuXQl4GtgN5GWBa5GWAadlKeTmRm4HtYbXcPOkCDQBW1t3vqqpdBzX/8yQXdvftQ59bh/azklw+tH+yqvYmefSwb29335AkVXX50HfNAg0AAAAAAADg8H3TsgMAYNM8OMkPVNV7qupPqurvDe0nJLlprt++oW219rupqvOqak9V7dm/f/8IoQMAAAAAAMDRTYEGwNFjR5L7Jzk9yf+W5A1VVZtx4O6+qLt3d/funTu3zKUMAQAAAAAAYDJc4gTg6LEvyZu7u5O8t6q+nuS4JDcnOWmu34lDW9ZoBwAAAAAAADaRFTQAjh7/OckPJUlVPTjJPZN8NskVSc6uqntV1clJTkny3iTvS3JKVZ1cVfdMcvbQFwAAAAAAANhkVtAA2IKq6rIkj0tyXFXtS/LCJBcnubiqrkvy1STnDqtpXF9Vb0jy4SR3JDm/u782HOd5Sd6e5JgkF3f39Qt/MQAAAAAAALANKNAA2IK6+5xVdv2TVfq/KMmLVmi/MsmVmxgaAAAAAAAAsAKXOAEAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAAAAAAAYmQINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJHtWHYAY9l1wVuXHcLobrzwKcsOAWDd5GUAFm07/PYkfn/gaCFnAUezqro4yY8mubW7Hza0vT7JqUOXY5N8obtPq6pdST6S5GPDvqu7+znDYx6V5JIk35LkyiQ/2929oJdxVNoOvz9+ewCmZTv89iR+f1jdUVugAQAAAADAJFyS5GVJXnOgobv/0YHtqvqNJF+c6/+J7j5theO8IslPJ3lPZgUaZyZ52+aHCwAA43CJEwAAAAAARtPd70py20r7qqqSPD3JZWsdo6qOT3Lf7r56WDXjNUmetsmhAgDAqBRoAAAAAACwLD+Q5DPd/fG5tpOr6oNV9SdV9QND2wlJ9s312Te03U1VnVdVe6pqz/79+8eJGgAAjoACDQAAAAAAluWc3HX1jFuSPLC7H5Hk+UleV1X3PZwDdvdF3b27u3fv3LlzE0MFAICN2bHsAAAAAAAA2H6qakeSf5jkUQfauvv2JLcP2++vqk8keXCSm5OcOPfwE4c2AADYMqygAQAAG1RVF1fVrVV13Vzb66vqmuF2Y1VdM7TvqqqvzO377bnHPKqqPlRVe6vqpcP1uAEA4Gj1+CQf7e5vXLqkqnZW1THD9ncnOSXJDd19S5IvVdXpwzj5GUnesoygAQDgSCnQAACAjbskyZnzDd39j7r7tO4+Lcmbkrx5bvcnDuzr7ufMtb8iyU9nNgl9ysHHBACAraiqLkvy7iSnVtW+qnr2sOvs3PXyJkny2CTXDgXOb0zynO6+bdj33CSvSrI3ySeSvG3s2AEAYDO5xAkAAGxQd7+rqnattG84u+/pSX54rWNU1fFJ7tvdVw/3X5PkaTHpDADAFtfd56zS/swV2t6UWYHzSv33JHnYpgYHAAALZAUNAAAY1w8k+Ux3f3yu7eSq+mBV/UlV/cDQdkKSfXN99g1td1NV51XVnqras3///nGiBgAAAABgUynQAACAcZ2Tuy7bfEuSB3b3I5I8P8nrquq+h3PA7r6ou3d39+6dO3duYqgAAAAAAIzFJU4AAGAkVbUjyT9M8qgDbd19e5Lbh+33V9Unkjw4yc1JTpx7+IlDGwAAAAAARwEraAAAwHgen+Sj3f2NS5dU1c6qOmbY/u4kpyS5obtvSfKlqjq9qirJM5K8ZRlBAwAAAACw+RRoAADABlXVZUneneTUqtpXVc8edp2du17eJEkem+TaqromyRuTPKe7bxv2PTfJq5LsTfKJJG8bO3YAAAAAABbDJU4AAGCDuvucVdqfuULbm5K8aZX+e5I8bFODAwAAAABgEqygAQAAAAAAAAAwMgUaAAAAAAAAAAAjU6ABAAAAAAAAADAyBRoAAAAAAAAAACNToAEAAAAAAADbSFVdXFW3VtV1K+z7+arqqjpuuF9V9dKq2ltV11bVI+f6nltVHx9u5y7yNQBsRYcs0JCgAQAAgK3EXAYAABzSJUnOPLixqk5K8sQkfz7X/KQkpwy385K8Yuh7/yQvTPKYJI9O8sKqut+oUQNscetZQeOSSNAAAADA1nFJzGUAAMCquvtdSW5bYdeLk/xCkp5rOyvJa3rm6iTHVtXxSX4kyVXdfVt3fz7JVVlhHA7AnQ5ZoCFBA0yPMwIBAGB15jIAAODwVdVZSW7u7j87aNcJSW6au79vaFutfaVjn1dVe6pqz/79+zcxaoCtZT0raNyNBA2wdJfEGYEAALBu5jIAAGB1VfWtSX4pyb8e4/jdfVF37+7u3Tt37hzjKQC2hMMu0JCgAZbPGYEAALB+5jIAAOCQHpTk5CR/VlU3JjkxyQeq6m8nuTnJSXN9TxzaVmsHYBVHsoKGBA0wQWOeEQgAAFucuQwAAFhDd3+ou/9Wd+/q7l2ZzRc/srs/neSKJM8YLqd9epIvdvctSd6e5IlVdb9hdeYnDm0ArOKwCzQkaIDpGfuMQEs2AwCwlZnLAACAu6qqy5K8O8mpVbWvqp69Rvcrk9yQZG+SVyZ5bpJ0921JfjXJ+4bbrwxtAKxix6E6DAn6cUmOq6p9SV7Y3a9epfuVSZ6cWYL+cpJnJbMEXVUHEnQiQQNstvkzApM7zwh8dNY+I/BxB7X/8UoH7+6LklyUJLt37+6V+gAAwFSYywAAgLV19zmH2L9rbruTnL9Kv4uTXLypwQEcxQ5ZoCFBA0xfd38oyd86cH9Ytnl3d3+2qq5I8ryqujzJYzKcEVhVb0/y74azAZPZGYEvWHDoAACw6cxlAAAAAFN02Jc4AWD5LD8HAAAAAAAAW8shV9AAYHqcEQgAAAAAAABbixU0AAAAAAAAAABGpkADAAAAAAAAAGBkCjQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAAAAARqZAAwAAAAAAAABgZAo0AAAAAAAAAABGpkADAAAAAAAAAGBkCjQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAGE1VXVxVt1bVdXNtv1xVN1fVNcPtyXP7XlBVe6vqY1X1I3PtZw5te6vqgkW/DgAA2CgFGgAAAAAAjOmSJGeu0P7i7j5tuF2ZJFX1kCRnJ3no8JiXV9UxVXVMkt9K8qQkD0lyztAXAAC2jB3LDgAAAAAAgKNXd7+rqnats/tZSS7v7tuTfLKq9iZ59LBvb3ffkCRVdfnQ98ObHS8AAIzFChoAAAAAACzD86rq2uESKPcb2k5IctNcn31D22rtd1NV51XVnqras3///jHiBgCAI6JAAwAAAACARXtFkgclOS3JLUl+Y7MO3N0Xdffu7t69c+fOzTosAABsmAINAADYoOGMv1ur6rq5tl+uqpur6prh9uS5fS+oqr1V9bGq+pG59jOHtr1VdcGiXwcAACxKd3+mu7/W3V9P8srceRmTm5OcNNf1xKFttXYAANgyFGgAAMDGXZLkzBXaX9zdpw23K5Okqh6S5OwkDx0e8/KqOqaqjknyW0melOQhSc4Z+gIAwFGnqo6fu/tjSQ4UO1+R5OyquldVnZzklCTvTfK+JKdU1clVdc/MxtRXLDJmAADYqB3LDgAAALa67n5XVe1aZ/ezklze3bcn+WRV7c2dZwvu7e4bkqSqLh/6fniz4wUAgEWqqsuSPC7JcVW1L8kLkzyuqk5L0kluTPLPkqS7r6+qN2Q2Dr4jyfnd/bXhOM9L8vYkxyS5uLuvX+wrAQCAjVGgAQAA43leVT0jyZ4kP9/dn09yQpKr5/rsG9qS5KaD2h+zkCgBAGBE3X3OCs2vXqP/i5K8aIX2K5NcuYmhAQDAQrnECQAAjOMVSR6U5LQktyT5jc06cFWdV1V7qmrP/v37N+uwAAAAAACMSIEGAACMoLs/091f6+6vJ3ll7ryMyc1JTprreuLQtlr7Sse+qLt3d/funTt3bn7wAAAAAABsOgUaAAAwgqo6fu7ujyW5bti+IsnZVXWvqjo5ySlJ3pvkfUlOqaqTq+qeSc4e+gIAAAAAcBTYsewAAABgq6uqy5I8LslxVbUvyQuTPK6qTkvSSW5M8s+SpLuvr6o3JPlwkjuSnN/dXxuO87wkb09yTJKLu/v6xb4SAAAAAADGokADAAA2qLvPWaH51Wv0f1GSF63QfmWSKzcxNAAAAAAAJsIlTgAAAAAAAAAARqZAAwAAAAAAAABgZAo0AAAAAAAAYJuoqour6taqum6u7T9U1Uer6tqq+r2qOnZu3wuqam9VfayqfmSu/cyhbW9VXbDglwGwJR2yQEOSBgAAALYScxkAALCmS5KceVDbVUke1t0PT/Lfk7wgSarqIUnOTvLQ4TEvr6pjquqYJL+V5ElJHpLknKEvAGtYzwoal0SSBgAAALaOS2IuAwAAVtTd70py20Ft7+juO4a7Vyc5cdg+K8nl3X17d38yyd4kjx5ue7v7hu7+apLLh74ArOGQBRqSNMD0OCMQAABWZy4DAAA25KeSvG3YPiHJTXP79g1tq7WvqKrOq6o9VbVn//79mxwuwNaxnhU0DmXTkzQAh3RJnBEIAABHalPnMkw2AwBwtKiqf5XkjiSv3czjdvdF3b27u3fv3LlzMw8NsKVsqEBjjCRtUgPg0JwRCAAAR2aMuQyTzQAAHA2q6plJfjTJT3R3D803JzlprtuJQ9tq7QCs4YgLNMZK0iY1ADaF1Y0AAOAgJpwBAGBlVXVmkl9I8tTu/vLcriuSnF1V96qqk5OckuS9Sd6X5JSqOrmq7pnZKs5XLDpugK3miAo0JGmA6bK6EQAA3J25DAAAmKmqy5K8O8mpVbWvqp6d5GVJ7pPkqqq6pqp+O0m6+/okb0jy4SR/kOT87v7asJrz85K8PclHkrxh6AvAGnYcqsOQpB+X5Liq2pfkhUlekORemSXpJLm6u5/T3ddX1YEkfUeGJD0c50CSPibJxZI0wOabOyPwjHWcEZg12u+iuy9KclGS7N69u1fqAwAAU2EuAwAAVtfd56zQ/Oo1+r8oyYtWaL8yyZWbGBrAUe+QBRqSNMDWMHdG4A+ucEbg66rqPyb5ztx5RmBlOCMws8KMs5P848VGDQAAm89cBgAAADBFhyzQAGB6nBEIAAAAAAAAW4sCDYAtyBmBAAAAAAAAsLV807IDAAAAAAAAAAA42inQAAAAAAAAAAAYmQINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAAAAAAAYmQINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAABgNFV1cVXdWlXXzbX9h6r6aFVdW1W/V1XHDu27quorVXXNcPvtucc8qqo+VFV7q+qlVVVLeDkAAHDEFGgAAAAAADCmS5KceVDbVUke1t0PT/Lfk7xgbt8nuvu04facufZXJPnpJKcMt4OPCQAAk6ZAAwAAAACA0XT3u5LcdlDbO7r7juHu1UlOXOsYVXV8kvt299Xd3Ulek+RpI4QLAACjUaABAAAAAMAy/VSSt83dP7mqPlhVf1JVPzC0nZBk31yffUPb3VTVeVW1p6r27N+/f5yIAQDgCCjQAAAAAABgKarqXyW5I8lrh6Zbkjywux+R5PlJXldV9z2cY3b3Rd29u7t379y5c3MDBgCADVCgAQAAG1RVF1fVrVV13Vzbf6iqj1bVtVX1e1V17NC+q6q+UlXXDLffnnvMo6rqQ1W1t6peWlW1hJcDAAALUVXPTPKjSX5iuGxJuvv27v7csP3+JJ9I8uAkN+eul0E5cWgDAIAtQ4EGAABs3CVJzjyo7aokD+vuhyf570leMLfvE9192nB7zlz7K5L8dJJThtvBxwQAgKNCVZ2Z5BeSPLW7vzzXvrOqjhm2vzuzcfEN3X1Lki9V1elDIfMzkrxlCaEDAMARU6ABAAAb1N3vSnLbQW3v6O47hrtX565n+91NVR2f5L7dffVw9uBrkjxthHABAGChquqyJO9OcmpV7auqZyd5WZL7JLnqoJXlHpvk2qq6Jskbkzynuw+MtZ+b5FVJ9ma2ssbbFvgyAABgw3YsOwAAANgGfirJ6+fun1xVH0zypST/e3f/tyQnJNk312ff0HY3VXVekvOS5IEPfOAoAQMAwGbp7nNWaH71Kn3flORNq+zbk+RhmxgaAAAslBU0AABgRFX1r5LckeS1Q9MtSR7Y3Y9I8vwkr6uq+x7OMbv7ou7e3d27d+7cubkBAwAAAAAwCitoAADASKrqmUl+NMkZw2VL0t23J7l92H5/VX0iyYOT3Jy7XgblxKENAAAAAICjgBU0AABgBFV1ZpJfSPLU7v7yXPvOqjpm2P7uJKckuaG7b0nypao6vaoqyTOSvGUJoQMAAAAAMAIraAAAwAZV1WVJHpfkuKral+SFSV6Q5F5JrprVW+Tq7n5Okscm+ZWq+pskX0/ynO6+bTjUc5NckuRbkrxtuAEAAAAAcBRQoAEAABvU3ees0PzqVfq+KcmbVtm3J8nDNjE0AAAAAAAmwiVOAAAAgKNKVV1cVbdW1XVzbfevqquq6uPDn/cb2quqXlpVe6vq2qp65Nxjzh36f7yqzl3GawEAgDEYMwMsxyELNCRoAAAAYIu5JMmZB7VdkOSd3X1KkncO95PkSUlOGW7nJXlFMpv7yOySVY9J8ugkLzww/wEAAEeBS2LMDLBw61lB45JI0ACTongOAABW193vSnLbQc1nJbl02L40ydPm2l/TM1cnObaqjk/yI0mu6u7buvvzSa7K3edHAABgSzJmBliOQxZoSNAAk3RJFM8BAMDheEB33zJsfzrJA4btE5LcNNdv39C2WvvdVNV5VbWnqvbs379/c6MGAIDFMWYGGNl6VtBYiQQNsESK5wAA4Mh1dyfpTTzeRd29u7t379y5c7MOCwAAS2PMDDCOIy3Q+AYJGmAyFM8BAMDqPjMUKmf489ah/eYkJ831O3FoW60dAACOVsbMACM70gINCRpgwhTPAQDA3VyR5Nxh+9wkb5lrf0bNnJ7ki0Ph89uTPLGq7jdcCvCJQxsAABytjJkBRnakBRoSNMD0KJ4DAIAkVXVZkncnObWq9lXVs5NcmOQJVfXxJI8f7ifJlUluSLI3ySuTPDdJuvu2JL+a5H3D7VeGNgAA2PKMmQGWY8ehOgwJ+nFJjquqfUlemFlCfsOQrD+V5OlD9yuTPDmzBP3lJM9KZgm6qg4k6ESCBhjDgeK5C3P34rnnVdXlSR6ToXiuqt6e5N8NhXPJrHjuBQuOGQAANl13n7PKrjNW6NtJzl/lOBcnuXgTQwMAgEkwZgZYjkMWaEjQANOjeA4AAGCadl3w1mWHMLobL3zKskMAAADYkg5ZoAHLtB0mNRITGxw+xXMAAAAAAACwtXzTsgMAAAAAAAAAADjaKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAAAAAAAYmQINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAAAAAAAYmQINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAARlNVF1fVrVV13Vzb/avqqqr6+PDn/Yb2qqqXVtXeqrq2qh4595hzh/4fr6pzl/FaAABgIxRoAAAAAAAwpkuSnHlQ2wVJ3tndpyR553A/SZ6U5JThdl6SVySzgo4kL0zymCSPTvLCA0UdAACwVSjQAAAAAABgNN39riS3HdR8VpJLh+1Lkzxtrv01PXN1kmOr6vgkP5Lkqu6+rbs/n+Sq3L3oAwAAJk2BBgAAAAAAi/aA7r5l2P50kgcM2yckuWmu376hbbX2u6mq86pqT1Xt2b9//+ZGDQAAG6BAAwAANsg1tQEA4Mh1dyfpTTzeRd29u7t379y5c7MOCwAAG6ZAAwAANu6SuKY2AAAcjs8Mly7J8OetQ/vNSU6a63fi0LZaOwAAbBkKNAAAYINcUxsAAA7bFUkOrBp3bpK3zLU/Y1h57vQkXxwuhfL2JE+sqvsNhcxPHNoAAGDL2LHsAAAA4Cg16jW1M1t9Iw984AM3MWQAANh8VXVZksclOa6q9mW2ctyFSd5QVc9O8qkkTx+6X5nkyUn2JvlykmclSXffVlW/muR9Q79f6e6Di6QBAGDSFGgAAMDIururalOvqZ3koiTZvXv3ph0XAADG0N3nrLLrjBX6dpLzVznOxUku3sTQAABgoVziBAAAxuGa2gAAAAAAfIMCDQAAGIdragMAAAAA8A0KNAAAYIOGa2q/O8mpVbVvuI72hUmeUFUfT/L44X4yu6b2DZldU/uVSZ6bzK6pneTANbXfF9fUBhhFVf3Lqrq+qq6rqsuq6pur6uSqek9V7a2q11fVPYe+9xru7x3271py+AAAMCrjZYBxbahAQ5IGAIDZNbW7+/juvkd3n9jdr+7uz3X3Gd19Snc//kCxRc+c390P6u7v6e49c8e5uLv/znD7neW9IoCjU1WdkORnkuzu7oclOSbJ2Ul+LcmLu/vvJPl8kmcPD3l2ks8P7S8e+gEAwFHJeBlgfEdcoCFJA0yT4jkAAFjTjiTfUlU7knxrkluS/HCSNw77L03ytGH7rOF+hv1nVFUtLlQAAFg442WAEW30EieSNMCEKJ4DAIDVdffNSX49yZ9nNofxxSTvT/KF7r5j6LYvyQnD9glJbhoee8fQ/zsWGTMAACzKmOPlqjqvqvZU1Z79+/eP9yIAJu6ICzTGStISNMCGKZ4DAIAVVNX9MhsDn5zkO5N8W5IzN+G45jIAANjyxhovJ0l3X9Tdu7t7986dOzfjkABb0kYucTJKkpagAY6c4jkAAFjT45N8srv3d/ffJHlzku9PcuxQ4JwkJya5edi+OclJSTLs//Yknzv4oOYyAAA4SowyXgbgThu5xIkkDTAxiucAAGBNf57k9Kr61mHluDOSfDjJHyX58aHPuUneMmxfMdzPsP8Pu7sXGC8AACyS8TLAyHYcusuqvpGkk3wlsyS9J3cm6cuzcpJ+dyRpgLF8o3guSarqLsVzwyoZKxXP7VM8BwDA0a6731NVb0zygSR3JPlgkouSvDXJ5VX1b4e2Vw8PeXWS/1RVe5PcluTsxUcNAACLYby8fLsueOuyQwBGdsQFGpI0wCQpngMAgDV09wuTvPCg5huSPHqFvn+d5H9ZRFwAADAFxssA49rIChqSNMDEKJ4DAAAAAACAadpQgQYA06N4DgAAAAAAAKbnm5YdAAAAAAAAAADA0U6BBgAAAAAAAADAyBRoAAAAAAAAAACMTIEGAAAAAAAAAMDIFGgAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAAADAyBRoAAAAAAAAAACMbMeyAwCAo8WuC9667BAW4sYLn7LsEAAAAAAAALYcK2gAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAAADAyBRoAAAAAAAAAACMTIEGAAAAAAAAAMDIFGgAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAC1dVp1bVNXO3L1XVz1XVL1fVzXPtT557zAuqam9VfayqfmSZ8QMAwOHasewAAAAAAADYfrr7Y0lOS5KqOibJzUl+L8mzkry4u399vn9VPSTJ2UkemuQ7k/zXqnpwd39tkXEDAMCRsoIGAAAAAADLdkaST3T3p9boc1aSy7v79u7+ZJK9SR69kOgAAGATKNAAAICRWLIZAADW7ewkl83df15VXVtVF1fV/Ya2E5LcNNdn39B2F1V1XlXtqao9+/fvHy9iAAA4TAo0AABgJN39se4+rbtPS/KoJF/ObMnmZLZk82nD7crkbks2n5nk5cNSzwAAcNSqqnsmeWqS3x2aXpHkQZld/uSWJL9xOMfr7ou6e3d37965c+dmhgoAABuiQAMAABbDks0AALCyJyX5QHd/Jkm6+zPd/bXu/nqSV+bOMfHNSU6ae9yJQxsAAGwJCjQAAGAxLNkMAAArOydzY+WqOn5u348luW7YviLJ2VV1r6o6OckpSd67sCgBAGCDFGgAAMDILNkMAAArq6pvS/KEJG+ea/73VfWhqro2yQ8l+ZdJ0t3XJ3lDkg8n+YMk53f31xYcMgAAHLEdyw4AAAC2gbst2XxgR1W9MsnvD3ct2QwAwLbS3X+V5DsOavvJNfq/KMmLxo4LYLuqqmOTvCrJw5J0kp9K8rEkr0+yK8mNSZ7e3Z+vqkrym0menOTLSZ7Z3R9YfNQAW8eGVtCoqmOr6o1V9dGq+khV/f2qun9VXVVVHx/+vN/Qt6rqpVW1d1jK+ZGb8xIAAGDyLNkMMBHmMgAAYE2/meQPuvvvJvneJB9JckGSd3b3KUneOdxPZieknDLczstsxVAA1rDRS5xI0gATY8IZYFos2QwwOeYyAABgBVX17Ukem+TVSdLdX+3uLyQ5K8mlQ7dLkzxt2D4ryWt65uokxx50UgoABzniAg1JGmCyTDgDTEh3/1V3f0d3f3Gu7Se7+3u6++Hd/dTuvmVu34u6+0HdfWp3v205UQMcncxlAADAmk5Osj/J71TVB6vqVcOJJw+Ym7v4dJIHDNsnJLlp7vH7hjYAVrGRFTRGSdJVdV5V7amqPfv3799AeADbjwlnAABYk7kMAABY3Y4kj0zyiu5+RJK/yp0n+yVJuruT9OEe2JgZYGYjBRqjJOnuvqi7d3f37p07d24gPIBtyYQzAACszlwGAACsbl+Sfd39nuH+GzMbP3/mwIl9w5+3DvtvTnLS3ONPHNruxpgZYGYjBRqjJWkAjpgJZwAAWJ25DAAAWEV3fzrJTVV16tB0RpIPJ7kiyblD27lJ3jJsX5HkGTVzepIvzl/GFYC7O+ICDUkaYJJMOAMAwCrMZQAAwCH9iySvraprk5yW5N8luTDJE6rq40keP9xPkiuT3JBkb5JXJnnuwqMF2GJ2bPDxB5L0PTNLwM/KrOjjDVX17CSfSvL0oe+VSZ6cWZL+8tAXgE3U3Z+uqpuq6tTu/ljunHD+cGYTzRfm7hPOz6uqy5M8JiacAQA4+pnLAACAVXT3NUl2r7DrjBX6dpLzx44J4GiyoQINSRpgkkw4AwDAKsxlAAAAAMuy0RU0AJgYE84AAAAAAAAwPd+07AAAAAAAAAAAAI52CjQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAAAAARqZAAwAAAAAAAABgZAo0AAAAAAAAAABGpkADAAAAAAAAAGBkCjQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAAAAARqZAAwAAAAAAAABgZAo0AAAAAAAAAABGpkADAAAAAAAAAGBkCjQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAAAAARqZAAwAAAAAAAABgZAo0AAAAAAAAAABGpkADAAAAAAAAAGBkCjQAAAAAAAAAAEamQAMAAAAAAAAAYGQKNAAAAAAAAAAARqZAAwAAAACApaiqG6vqQ1V1TVXtGdruX1VXVdXHhz/vN7RXVb20qvZW1bVV9cjlRg8AAIdnx7IDAAAAAABgW/uh7v7s3P0Lkryzuy+sqguG+7+Y5ElJThluj0nyiuFPWNWuC9667BBGd+OFT1l2CADAOllBAwAARuSMQAAAOGxnJbl02L40ydPm2l/TM1cnObaqjl9CfAAAcEQUaAAAwPh+qLtP6+7dw/0DZwSekuSdw/3krmcEnpfZGYEAAHA06yTvqKr3V9V5Q9sDuvuWYfvTSR4wbJ+Q5Ka5x+4b2gAAYEtwiRMAAFi8s5I8bti+NMkfZ7Zk8zfOCExydVUdW1XHz01OAwDA0eYfdPfNVfW3klxVVR+d39ndXVV9OAccCj3OS5IHPvCBmxcpAABskBU0AABgXJt+RmBVnVdVe6pqz/79+8eKGwAARtfdNw9/3prk95I8OslnDly6ZPjz1qH7zUlOmnv4iUPbwce8qLt3d/funTt3jhk+AAAclg0XaFTVMVX1war6/eH+yVX1nuG62a+vqnsO7fca7u8d9u/a6HMDAMAW8A+6+5GZXb7k/Kp67PzOYbWMwzoj0IQzwMaYywCYhqr6tqq6z4HtJE9Mcl2SK5KcO3Q7N8lbhu0rkjyjZk5P8kWrzQFsPuNlgPFsxgoaP5vkI3P3fy3Ji7v77yT5fJJnD+3PTvL5of3FQz8ANpnBM8C0jHFGIAAbZi4DYBoekORPq+rPkrw3yVu7+w+SXJjkCVX18SSPH+4nyZVJbkiyN8krkzx38SEDbAvGywAj2VCBRlWdmOQpSV413K8kP5zkjUOXS5M8bdg+a7ifYf8ZQ38ANpfBM8BEOCMQYHrMZQBMR3ff0N3fO9we2t0vGto/191ndPcp3f347r5taO/uPr+7H9Td39Pde5b7CgCOPsbLAOPa6AoaL0nyC0m+Ptz/jiRf6O47hvvz18z+xvW0h/1fHPrfhetpAxw5g2eAyXFGIMD0vCTmMgAAYDUvySaPlxNjZoADjrhAo6p+NMmt3f3+TYzH9bQBNuYlMXgGmAxnBAJMi7kMAABY3Vjj5cSYGeCAHRt47PcneWpVPTnJNye5b5LfTHJsVe0Y/rNv/prZB66nva+qdiT59iSf28DzAzBnfvBcVY/bzGN390VJLkqS3bt392YeGwAAFshcBgAArM54GWBkR7yCRne/oLtP7O5dSc5O8ofd/RNJ/ijJjw/dDr6e9oHrbP/40N9/8gFsngOD5xuTXJ7ZpU2+MXge+qw0eI7BMwAA24G5DAAAWJ3xMsD4jrhAYw2/mOT5VbU3s6XyXz20vzrJdwztz09ywQjPDbBtGTwDAMARM5cBAACrM14G2CQbucTJN3T3Hyf542H7hiSPXqHPXyf5Xzbj+QA4LL+Y5PKq+rdJPpi7Dp7/0zB4vi2zog4AANgWzGUAAMDqjJcBxrEpBRoATIvBMwAAAAAAAEzLGJc4AQAAAAAAAABgjgINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAAAAAAAYmQINAAAAAAAAAICRKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGNmOZQcAAAAs3q4L3rrsEAAAAAAAthUraAAAAAAAAAAAjEyBBgAAAAAAAADAyBRoAAAAAAAAAACMTIEGAAAAAAAAAMDIFGgAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAAADAyBRoAAAAAAAAAACMTIEGAAAAAAAAAMDIFGgAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAC1dVJ1XVH1XVh6vq+qr62aH9l6vq5qq6Zrg9ee4xL6iqvVX1sar6keVFDwAAh0+BBgAAjMSEMwAArOmOJD/f3Q9JcnqS86vqIcO+F3f3acPtyiQZ9p2d5KFJzkzy8qo6ZhmBAwDAkdix7AAAAOAodmDC+QNVdZ8k76+qq4Z9L+7uX5/vfNCE83cm+a9V9eDu/tpCowYAgAXo7luS3DJs/0VVfSTJCWs85Kwkl3f37Uk+WVV7kzw6ybtHDxYAADbBEa+gscbZgPevqquq6uPDn/cb2quqXjqcDXhtVT1ys14EAABMUXff0t0fGLb/Ism6J5y7+5NJDkw4A7AJzGUATFdV7UryiCTvGZqeN+Teiw/k5czG0jfNPWxf1h5fA3AYjJcBxreRS5ystvzcBUne2d2nJHnncD9JnpTklOF2XpJXbOC5AViBATTAdJlwBpgEcxkAE1RV907ypiQ/191fyizfPijJaZmtsPEbh3m886pqT1Xt2b9//2aHC3A0M14GGNkRF2iscTbgWUkuHbpdmuRpw/ZZSV7TM1cnObaqjj/S5wdgRQbQABNkwhlgGsxlAExPVd0js7Hya7v7zUnS3Z/p7q9199eTvDJ3rip3c5KT5h5+4tB2F919UXfv7u7dO3fuHPcFABxFjJcBxreRFTS+4aCzAR8wXDswST6d5AHDtrMBAUZmAA0wPSacAabJXAbA8lVVJXl1ko9093+ca5+fm/ixJNcN21ckObuq7lVVJ2d2wsl7FxUvwHay2eNlJ5sAzGy4QGOFswG/obs7SR/m8SRogE2wmQNouRngyJhwBpgmcxkAk/H9SX4yyQ9X1TXD7clJ/n1Vfaiqrk3yQ0n+ZZJ09/VJ3pDkw0n+IMn53f21JcUOcNTa7PHy8DgnmwAk2bGRB690NmCSz1TV8d19yzDxfOvQvu6zAZNclCS7d+8+7AQPwN0H0LP/H5zp7q6qw8qvcjPAETsw4fyhqrpmaPulJOdU1WmZTWjcmOSfJbMJ56o6MOF8R0w4A2w6cxkA09Hdf5qkVth15RqPeVGSF40WFMA2N8Z4GYA7HfEKGqudDZjZWX/nDtvnJnnLXPszaub0JF+cO5sbgE2y1gB62G8ADbAg3f2n3V3d/fDuPm24XdndP9nd3zO0P3V+XNzdL+ruB3X3qd39tmXGD3C0MZcBAACrM14GGN9GVtBY7WzAC5O8oaqeneRTSZ4+7LsyyZOT7E3y5STP2sBzA7CCdQygL8zdB9DPq6rLkzwmBtAAABzdzGUAAMDqjJcBRnbEBRprLD+XJGes0L+TnH+kzwfAuhhAM7pdF7x12SGM7sYLn7LsEACAEZjLAACA1RkvA4xvIytoADAxBtAAsP0onAMAAACArUGBBgAAAAAAHGQ7FMICALBY37TsAAAAAAAAAAAAjnYKNAAAAAAAAAAARqZAAwAAAAAAAABgZAo0AAAAAAAAAABGtmPZAQAAAAAAAADA0WLXBW9ddgiju/HCpyw7hC3JChoAAAAAAAAAACNToAEAAAAAAAAAMDIFGgAAAAAAAAAAI1OgAQAAAAAAAAAwMgUaAAAAAAAAAAAjU6ABAAAAAAAAADAyBRoAAAAAAAAAACNToAEAAAAAAAAAMLIdyw4AAAAA1rLrgrcuO4TR3XjhU5YdAgAAAAAjs4IGAAAAAAAAAMDIFGgAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAAADAyBRoAAAAAAAAAACMbMeyAwAAmJpdF7x12SGM7sYLn7LsEAAAAABg3bbDnB1w9LOCBgAAAAAAAADAyBRoAAAAAAAAAACMTIEGAAAAAAAAAMDIFGgAAAAAAAAAAIxMgQYAAAAAAAAAwMgUaAAAAAAAAAAAjEyBBgAAAAAAAADAyHYs+gmr6swkv5nkmCSv6u4LFx0DAHeSlwGmRV4GmBZ5GWB65Ga4q10XvHXZISzEjRc+ZdkhsAp5GWD9FlqgUVXHJPmtJE9Isi/J+6rqiu7+8CLjABZvO/wjYSv+A0FeBpgWeRm2r+0wXk623phZXobtbTvk5q2WlxO5GWBq5GXYvoyXj8yiV9B4dJK93X1DklTV5UnOSiJJAyyHvAzblMHzZMnLANMiLwNMj9wMMC3yMsBhWHSBxglJbpq7vy/JY+Y7VNV5Sc4b7v5lVX3sCJ/ruCSfPcLHjmHT46lfO+KHHvXvzQYtPJ5D/F1u+/dnDVOKJfVrRxzPd212LIfhkHk52bTcPKm/ryOwlePfyrEn4l+2LRv/BvJysrzcvJ3zsnjWNqV4phRLIp5DmVQ8W3DMLC9vMnMZo1loPOYxNmRS8WzBvJxs3znmKcWSiOdQxLO6I45lA+OItUzpvUmOPJ5J5+XEmHkBphRLIp5DEc/qphTLKHPMiy7QOKTuvijJRRs9TlXt6e7dmxDSpphSPFOKJRHPoYhndVOKJZlePJtpM3LzVn9/tnL8Wzn2RPzLtpXj38qxH8rRmJfFs7YpxTOlWBLxHIp4FkNeHp941jaleKYUSyKeQ5laPJvlaJxjnlIsiXgORTyrm1IsiXgWyZh5XFOKJRHPoYhndVOKJRknnm/azIOtw81JTpq7f+LQBsByyMsA0yIvA0yLvAwwPXIzwLTIywCHYdEFGu9LckpVnVxV90xydpIrFhwDAHeSlwGmRV4GmBZ5GWB65GaAaZGXAQ7DQi9x0t13VNXzkrw9yTFJLu7u60d6ug0vYbfJphTPlGJJxHMo4lndlGJJphfPIW3zvHy4tnL8Wzn2RPzLtpXj33Kxb/O8LJ61TSmeKcWSiOdQxLMB8vKkiGdtU4pnSrEk4jmUqcVzSNs4N08plkQ8hyKe1U0plkQ8G7aN83IyrXimFEsinkMRz+qmFEsyQjzV3Zt9TAAAAAAAAAAA5iz6EicAAAAAAAAAANuOAg0AAAAAAAAAgJFt+QKNqjqzqj5WVXur6oIV9t+rql4/7H9PVe1aYizPrKr9VXXNcPunY8UyPN/FVXVrVV23yv6qqpcO8V5bVY9cYiyPq6ovzr03/3qsWIbnO6mq/qiqPlxV11fVz67QZ5Hvz3riWch7VFXfXFXvrao/G2L5Nyv0WeT3aj3xLPS7NTznMVX1war6/RX2Lez92QrW8/meqvV8/raCtT6vU1dVN1bVh4bv9p5lx3M4qurYqnpjVX20qj5SVX9/2TGtV1WdOpdTr6mqL1XVzy07rsNRVf9y+N5eV1WXVdU3LzumZZjSeHCd8WzbMeGUxoPDcxkTri+uyYwJDxHLov8tuubv96Jzz9TUhOYx1hnPwj4/frfWjGUyv1mHEY/frQn9bk3pN2tq5OU1Y5GX145nMrlZXt6UeLb1vyemZkq5eUp5eXi+yeRmeXlT4tmWuXnb5+Xu3rK3JMck+USS705yzyR/luQhB/V5bpLfHrbPTvL6JcbyzCQvW+D789gkj0xy3Sr7n5zkbUkqyelJ3rPEWB6X5PcX+N4cn+SRw/Z9kvz3Ff6+Fvn+rCeehbxHw+u997B9jyTvSXL6QX0W8r06jHgW+t0anvP5SV630t/JIt+frXBbz+d7qrf1fP62wm2tz+vUb0luTHLcsuM4wtgvTfJPh+17Jjl22TEd4es4Jsmnk3zXsmM5jJhPSPLJJN8y3H9DkmcuO64lvReTGQ+uM55tOyac0nhweC5jwvXFNZkx4SFiWeh7c6jf70XnnindMqF5jMOIZ2GfH79ba8Yymd+sw4jH79ba8Sw6N0/mN2tKN3n5kPHIy2vHM5ncLC9vSjwLzcvDc8rNK78vk8nNU8vLw/NNJjfLy5sSz7bMzds9L2/1FTQenWRvd9/Q3V9NcnmSsw7qc1Zm/0GSJG9MckZV1ZJiWajufleS29boclaS1/TM1UmOrarjlxTLQnX3Ld39gWH7L5J8JLP/zJm3yPdnPfEsxPB6/3K4e4/h1gd1W9T3ar3xLFRVnZjkKUletUqXhb0/W8GUPt+Ha4qfv8O1js8rI6iqb8/sHyivTpLu/mp3f2GpQR25M5J8ors/texADtOOJN9SVTuSfGuS/7HkeJZiSuPBdcazUFMaE07t99KY8NCmNCbcgr/3C809EzOleYz1xrMwfrdWN6XfrMOIZ2H8bq1tSr9ZEyQvr0FeXtuUcrO8vCnxLJTcvKYp5eZJ5eVkWrlZXt6UeBZmSrl5u+flrV6gcUKSm+bu78vdP9jf6NPddyT5YpLvWFIsSfI/D0vmvLGqThohjsOx3pgX5e8PS9m8raoeuqgnHZageURm1VnzlvL+rBFPsqD3aFjC55oktya5qrtXfW9G/l6tN55ksd+tlyT5hSRfX2X/Qt+freQQn+9JWufnb8pekrU/r1PXSd5RVe+vqvOWHcxhODnJ/iS/MyyJ9qqq+rZlB3WEzk5y2bKDOBzdfXOSX0/y50luSfLF7n7HcqOarKmNBxNjwkmMB4c4jAnX9pJMZ0x4qFiSxb43h/r9nmLuWZQpzWOsN55kOnMZU/zsLPx3a0q/WYeIJ/G7tVY8yeK+Wy/JdH6zpkZe3hh5eTCl3CwvH3E8yfb998TUTCk3b7W8nEwvN2/7vHyIeJJtmpu3c17e6gUaW81/SbKrux+e5KrcWWVD8oHMlk7/3iT/V5L/vIgnrap7J3lTkp/r7i8t4jk3EM/C3qPu/lp3n5bkxCSPrqqHjfVcmxTPwr5bVfWjSW7t7veP9RxHq6l939Zrat+Hw3GUfF7/QXc/MsmTkpxfVY9ddkDrtCOz5f1e0d2PSPJXSe52jcqpq6p7Jnlqkt9ddiyHo6rul1lF88lJvjPJt1XVP1luVKzTth8TTmU8mEzvN9CYcEOxLPrfolv195uVmctY3cJ/t6b0m7WOePxuTeB3a0q/WWwaeXl1/j0hL28knm357wk2hby8um2fl9cRz7bNzds5L2/1Ao2bk8xXy5w4tK3Yp2ZLXH97ks8tI5bu/lx33z7cfVWSR40Qx+FYz/u3EN39pQNL2XT3lUnuUVXHjfmcVXWPzBLia7v7zSt0Wej7c6h4lvEe9Ww5/j9KcuZBuxb1vVpXPAv+bn1/kqdW1Y2ZLWf2w1X1/xzUZynvz5St4/s2eWt8H6ZsPZ/XSRtWQkh335rk9zJbVnAr2Jdk31zV7xszK9jYap6U5APd/ZllB3KYHp/kk929v7v/Jsmbk3zfkmOaqsmMBxNjwimOB4fn+kKMCQ82pTHhIWNZ9L9F1/H7Pancs2BTmsdYVzwTm8uY1Gdn0Xl5Sr9Z64nH79ba8SzwuzWl36wpkpc3Zlvn5WRauVle3lg82/jfE1M0pdy81fJyMqHcvN3z8nrikZu3Z17e6gUa70tySlWdPJzheXaSKw7qc0WSc4ftH0/yh909xjVsDhlL3fUaRk/N7FpDy3RFkmfUzOmZLf99yzICqaq/XTW7Tk9VPTqzz+ZoX/jhuV6d5CPd/R9X6baw92c98SzqPaqqnVV17LD9LUmekOSjB3Vb1PdqXfEs8rvV3S/o7hO7e1dm3/M/7O6Dz8pe2PuzFazz+zZJ6/w+TNY6P6+TVVXfVlX3ObCd5IlJrltuVOvT3Z9OclNVnTo0nZHkw0sM6Uidky12eZPBnyc5vaq+dchBZ2T5466pmsx4MNneY8IpjQeH4xsTrmFKY8L1xLLI92adv9+Tyj0LNqV5jHXFM7G5jEl9dhaclyfzm7XeePxuTeN3a0q/WRMlL2/Mts3Lw3NMJjfLyxuPZ7v+e2KippSbt1peTiaUm7dzXl5vPNs1N2/3vLzjiCOdgO6+o6qel+TtSY5JcnF3X19Vv5JkT3dfkdkH/z9V1d4kt2X2pi4rlp+pqqcmuWOI5ZljxHJAVV2W5HFJjquqfUlemOQeQ7y/neTKJE9OsjfJl5M8a4mx/HiSf15VdyT5SpKzRx5sfH+Sn0zyoZpd3yhJfinJA+diWtj7s854FvUeHZ/k0qo6JrMfgjd09+8v43t1GPEs9Lu1kiW+P1vBip/voRp06lb8/C05pu3kAUl+bxif7kjyuu7+g+WGdFj+RZLXDv94uyHj/o5supr9p9oTkvyzZcdyuLr7PVX1xsyWCLwjyQeTXLTcqJZjSuPBdcaznceEUxoPJsaER2RKY8Ilvjcr/n5X1XOS5eSeKZnSPMZhxLOwz4/frTVN6TdrvfH43Zrw79aUfrOWSV5em7x8SFPKzfLyxuPx74mJmFJunlpeTqaVm+XlTYlnu+bmbZ2Xa/sU3AEAAAAAAAAALMdWv8QJAAAAAAAAAMDkKdAAAAAAAAAAABiZAg0AAAAAAAAAgJEp0AAAAAAAAAAAGJkCDQAAAAAAAACAkSnQAAAAAAAAAAAYmQINAAAAAAAAAICR/f8BbRj0UmWybxsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2160x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len= 2500\n"
     ]
    }
   ],
   "source": [
    "inst=[4,4,[2,2,2,2,2,2]]\n",
    "size=3000\n",
    "size_=10000\n",
    "import numpy as np\n",
    "# mean=np.arange(1,ship_num+1)\n",
    "mean=np.array([0.8,1,3,3.2,3.5,5.5])\n",
    "covl=[2 for i in range(ship_num)]\n",
    "# a=list(a)\n",
    "# a=random.sample(a,ship_num)\n",
    "# mean=np.sort(a)\n",
    "cov=np.zeros((ship_num,ship_num))\n",
    "for i in range(ship_num):\n",
    "    for j in range(ship_num):\n",
    "        if i==j:\n",
    "            cov[i][i]=covl[1]\n",
    "for i in range(ship_num):\n",
    "    for j in range(ship_num):\n",
    "        if i!=j:\n",
    "            cov[i][j]=0\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,6,figsize=(30,5),tight_layout=True)\n",
    "for g in range(1,6):\n",
    "  prob=[]\n",
    "  ship_num=len(inst[2])\n",
    "  robust(ship_num,inst[0],inst[1],inst[2],g,size_,mean,cov)\n",
    "  prob+=list(penalty_r)\n",
    "  # print(prob)\n",
    "  # data+=(tuple(prob),)\n",
    "  # l.append(\"Gamma=\"+str(g))\n",
    "  # print(\"data=\",data)\n",
    "# plt.boxplot(data,labels=l)\n",
    "# plt.show()\n",
    "\n",
    "  ax[g].hist(prob,bins=5)\n",
    "  ax[g].set_title(\"Gamma=\"+str(g))\n",
    "ax[0].hist(penalty_cvar,bins=5)\n",
    "ax[0].set_title(\"75%-CVaR\")\n",
    "plt.show()\n",
    "print(\"len=\",len(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_2 = np.random.multivariate_normal(mean, cov, size=size_)\n",
    "\n",
    "OR_=np.argsort(data_2)\n",
    "OR_=OR_+np.ones((size_,ship_num)).astype(int)\n",
    "OR=OR_.tolist()\n",
    "penalty_cvar=[]\n",
    "for k in OR:\n",
    "    OR2=k\n",
    "    a=0\n",
    "    for j in range(inst[0]):\n",
    "        for i in range(1,inst[1]):\n",
    "            for i_ in range(i+1,inst[1]+1):\n",
    "                if result[i-1][j]!=0 and result[i_-1][j]!=0:\n",
    "                    if OR2.index(result[i-1][j])>OR2.index(result[i_-1][j]):\n",
    "                        # print(j+1,height-i+1,O)\n",
    "                        a+=1\n",
    "                        # print(\"penalty!\")\n",
    "                            # print(i,i_,j+1,O)\n",
    "                        break\n",
    "    penalty_cvar.append(a)\n",
    "penalty_cvar=np.sort(penalty_cvar)\n",
    "import matplotlib.pyplot as plt\n",
    "penalty_cvar=penalty_cvar[round(0.75*size_):]\n",
    "# plt.hist(penalty_cvar,bins=50)\n",
    "plt.boxplot(penalty_cvar)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bc652a6662848c169ddaad7e75fc7966486f1f662e7670e7ffb2b305ef6abae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
