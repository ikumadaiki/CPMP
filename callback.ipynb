{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本研究"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio.constants import SENDFILE_FALLBACK_READBUFFER_SIZE\n",
    "import random\n",
    "from random import seed\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "class CuttingPlaneAlgorithm:\n",
    "    def __init__(self,ship_num,stack_num,height,n_init,size,size_,beta,mean,cov,OC,zk,aaa):\n",
    "        self.ship_num=ship_num\n",
    "        self.stack_num=stack_num\n",
    "        self.height=height\n",
    "        self.n_init=n_init\n",
    "        self.beta=beta\n",
    "        self.size=size\n",
    "        self.size_=size_\n",
    "        self.mean=mean\n",
    "        self.cov=cov\n",
    "        self.OC=OC\n",
    "        self.zk=zk\n",
    "        self.O1=[i+1 for i in range(self.ship_num)]\n",
    "        self.S=[i+1 for i in range(self.stack_num)]\n",
    "        self.H=[i+1 for i in range(self.height)]\n",
    "        self.P=[i+1 for i in range(self.ship_num)]\n",
    "        self.f=stack_num*height-sum(self.n_init)\n",
    "        self.aaa=aaa\n",
    "\n",
    "        # 期待値と分散共分散行列の準備\n",
    "        data_1 = np.random.multivariate_normal(mean, cov, size=self.size)\n",
    "\n",
    "        O_=np.argsort(data_1)\n",
    "        O_=O_+np.ones((size,ship_num)).astype(int)\n",
    "        global O\n",
    "        self.O=O_.tolist()\n",
    "        O=self.O\n",
    "\n",
    "    def get_penalty(self,result):\n",
    "        self.result=result\n",
    "        self.penalty=[]\n",
    "        for k in self.O:\n",
    "            OO=k\n",
    "            a=0\n",
    "            for j in range(self.stack_num):\n",
    "                for i in range(1,self.height):\n",
    "                    for i_ in range(i+1,self.height+1):\n",
    "                        if self.result[i-1][j]!=0 and self.result[i_-1][j]!=0:\n",
    "                            if OO.index(self.result[i-1][j])>OO.index(self.result[i_-1][j]):\n",
    "                                # print(j+1,height-i+1,O)\n",
    "                                a+=1\n",
    "                                # print(\"penalty!\")\n",
    "                                    # print(i,i_,j+1,O)\n",
    "                                break\n",
    "            self.penalty.append(a)\n",
    "        self.zk=[i for i, x in enumerate(self.penalty) if x-self.alpha_tmp>0]\n",
    "        \n",
    "        for zk_ in self.zk:\n",
    "            if not zk_ in self.aaa:\n",
    "                self.aaa.append(zk_)\n",
    "                self.OC.append(O[zk_])\n",
    "        return (self.zk,self.OC,self.penalty)\n",
    "\n",
    "    def solve(self):\n",
    "        def add_cutting_plane(model,where):\n",
    "            if where == GRB.callback.MIPSOL:\n",
    "                c_var,x_var,x_tmp={},{},{}\n",
    "                for var in self.model._vars:\n",
    "                    if \"u\" in var.VarName:\n",
    "                        u_var=var\n",
    "                    if \"alpha\" in var.VarName:\n",
    "                        alpha_var=var\n",
    "                        self.alpha_tmp=model.cbGetSolution(var)\n",
    "                    if \"c_\" in var.VarName:\n",
    "                        s=int(var.VarName.split(\"_\")[-3])\n",
    "                        h=int(var.VarName.split(\"_\")[-2])\n",
    "                        i=int(var.VarName.split(\"_\")[-1])\n",
    "                        c_var[s,h,i]=var\n",
    "                    if \"x_\" in var.VarName:\n",
    "                        s=int(var.VarName.split(\"_\")[-3])\n",
    "                        h=int(var.VarName.split(\"_\")[-2])\n",
    "                        p=int(var.VarName.split(\"_\")[-1])\n",
    "                        x_var[s,h,p]=var\n",
    "                        x_tmp[s,h,p]=model.cbGetSolution(var)\n",
    "                global result\n",
    "                result=self.get_result(x_tmp)\n",
    "                print(result)\n",
    "                zk,OC,penalty=self.get_penalty(result)\n",
    "                print(len(zk),len(OC))\n",
    "                for s in self.S:\n",
    "                    for h in range(2,len(self.H)+1):\n",
    "                        for h_ in range(1,h):\n",
    "                            for i,o in enumerate(OC):\n",
    "                                for j,p in enumerate(o):\n",
    "                                    model.cbLazy(c[s,h,i]>=quicksum(x[s,h,k] for k in o[j:])-quicksum(x[s,h_,k] for k in o[j:]))\n",
    "                model.cbLazy(u_var>=alpha_var+quicksum(quicksum(c_var[s,h,i] for s in self.S for h in self.H if h!=1)-alpha_var for i in zk)/((1-self.beta)*len(O)))\n",
    "        self.model=Model(\"CuttingPlaneCVaRMinimization\")\n",
    "        x,c,d={},{},{}\n",
    "        for s in self.S:\n",
    "            for h in self.H:\n",
    "                for p in self.P:\n",
    "                    x[s,h,p]=self.model.addVar(vtype=\"B\",name=\"x_\"+str(s)+\"_\"+str(h)+\"_\"+str(p))\n",
    "\n",
    "        for s in self.S:\n",
    "            for h in range(2,len(self.H)+1):\n",
    "                for i,o in enumerate(self.O):\n",
    "                    c[s,h,i]=self.model.addVar(vtype=\"c\",lb=0,name=\"c_\"+str(s)+\"_\"+str(h)+\"_\"+str(i))\n",
    "\n",
    "        for i in range(len(self.O)):\n",
    "            d[i]=self.model.addVar(vtype=\"C\",lb=0)\n",
    "        alpha=self.model.addVar(vtype=\"C\",lb=0,name=\"alpha\")\n",
    "        u=self.model.addVar(vtype=\"C\",lb=0,name=\"u\")\n",
    "\n",
    "        self.model.update()\n",
    "        self.model._vars=self.model.getVars()\n",
    "\n",
    "        for p in self.P:\n",
    "            self.model.addConstr(quicksum(x[s,h,p] for s in self.S for h in self.H)==self.n_init[p-1])\n",
    "\n",
    "        for s in self.S:\n",
    "            for h in self.H:\n",
    "                self.model.addConstr(quicksum(x[s,h,p] for p in self.P)<=1)\n",
    "\n",
    "        for s in self.S:\n",
    "            for h in range(1,len(self.H)):\n",
    "                self.model.addConstr(quicksum(x[s,h+1,p] for p in self.P)<=quicksum(x[s,h,p] for p in self.P))\n",
    "        # if len(self.OC)==0:\n",
    "        #     self.OC=[self.O1]\n",
    "        # else:\n",
    "        #     if self.O1 in self.OC:\n",
    "        #         self.OC=self.OC.remove(self.O1)\n",
    "        if len(self.OC)>self.size:\n",
    "            self.OC=self.OC[self.size:]\n",
    "        print(\"OC=\",self.OC)\n",
    "        for s in self.S:\n",
    "            for h in range(2,len(self.H)+1):\n",
    "                for i,o in enumerate([self.O1]):\n",
    "                    for j,p in enumerate(o):\n",
    "                        self.model.addConstr(quicksum(x[s,h,k] for k in o[j:])<=quicksum(x[s,h-1,k] for k in o[j:]))\n",
    "\n",
    "        for i in range(len([self.O1])):\n",
    "            self.model.addConstr(d[i]>=quicksum(c[s,h,i] for s in self.S for h in self.H if h!=1)-alpha)\n",
    "\n",
    "        self.model.addConstr(u>=alpha+quicksum(d[i] for i in range(len(self.O)))/((1-self.beta)*len(self.O)))\n",
    "        self.model.setObjective(u)\n",
    "        self.model._vars=self.model.getVars()\n",
    "        self.model.params.LazyConstraints = 1\n",
    "        self.model.params.TimeLimit = 3660\n",
    "        if self.f>=self.height:\n",
    "            self.model.optimize(add_cutting_plane)\n",
    "        else:\n",
    "            print(\"実行不可\")\n",
    "\n",
    "    def get_optimal_val(self):\n",
    "        if self.model.Status==GRB.OPTIMAL:\n",
    "            self.LB=self.model.ObjVal\n",
    "            return self.model.ObjVal\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_optimal_sol(self):\n",
    "        if self.model.Status==GRB.OPTIMAL:\n",
    "            x_opt={}\n",
    "            c_opt={}\n",
    "            for var in self.model._vars:\n",
    "                if \"x_\" in var.VarName:\n",
    "                    # print(var)\n",
    "                    s=int(var.VarName.split(\"_\")[-3])\n",
    "                    h=int(var.VarName.split(\"_\")[-2])\n",
    "                    p=int(var.VarName.split(\"_\")[-1])\n",
    "                    x_opt[s,h,p]=var.X\n",
    "                if \"c_\" in var.VarName:\n",
    "                    s=int(var.VarName.split(\"_\")[-3])\n",
    "                    h=int(var.VarName.split(\"_\")[-2])\n",
    "                    i=int(var.VarName.split(\"_\")[-1])\n",
    "                    c_opt[s,h,i]=var.X\n",
    "                if \"alpha\" in var.VarName:\n",
    "                    alpha_opt=var.X\n",
    "                if \"u\" in var.VarName:\n",
    "                    u_opt=var.X\n",
    "            return (x_opt,c_opt,alpha_opt,u_opt)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_result(self,x_tmp):\n",
    "        self.x_tmp=x_tmp\n",
    "        EPS=1.e-6\n",
    "        self.result=np.zeros((self.height,self.stack_num))\n",
    "        for (s,h,p) in self.x_tmp:\n",
    "            if self.x_tmp[s,h,p]>EPS:\n",
    "                self.result[self.height-h][s-1]=int(p)\n",
    "        self.result=self.result.astype(int)\n",
    "        return self.result\n",
    "    \n",
    "    # def get_penalty(self,result):\n",
    "    #     if self.model.Status==GRB.OPTIMAL:\n",
    "    #         self.result=result\n",
    "    #         self.penalty=[]\n",
    "    #         x,c,alpha,u=self.get_optimal_sol()\n",
    "    #         for k in self.O:\n",
    "    #             OO=k\n",
    "    #             a=0\n",
    "    #             for j in range(self.stack_num):\n",
    "    #                 for i in range(1,self.height):\n",
    "    #                     for i_ in range(i+1,self.height+1):\n",
    "    #                         if self.result[i-1][j]!=0 and self.result[i_-1][j]!=0:\n",
    "    #                             if OO.index(self.result[i-1][j])>OO.index(self.result[i_-1][j]):\n",
    "    #                                 # print(j+1,height-i+1,O)\n",
    "    #                                 a+=1\n",
    "    #                                 # print(\"penalty!\")\n",
    "    #                                     # print(i,i_,j+1,O)\n",
    "    #                                 break\n",
    "    #             self.penalty.append(a)\n",
    "    #         self.zk=[i for i, x in enumerate(self.penalty) if x-alpha>0]\n",
    "    #         for zk_ in self.zk:\n",
    "    #             self.OC.append(self.O[zk_])\n",
    "    #         return (self.zk,self.OC,self.penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OC= []\n",
      "Set parameter LazyConstraints to value 1\n",
      "Set parameter TimeLimit to value 3660\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 108 rows, 13098 columns and 1856 nonzeros\n",
      "Model fingerprint: 0xa1b91f55\n",
      "Variable types: 13002 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-03, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+00]\n",
      "{(1, 1, 1): 0.0, (1, 1, 2): 0.0, (1, 1, 3): 0.0, (1, 1, 4): 0.0, (1, 1, 5): 1.0, (1, 1, 6): 0.0, (1, 2, 1): 0.0, (1, 2, 2): 0.0, (1, 2, 3): 0.0, (1, 2, 4): 0.0, (1, 2, 5): 1.0, (1, 2, 6): 0.0, (1, 3, 1): 0.0, (1, 3, 2): 0.0, (1, 3, 3): 1.0, (1, 3, 4): 0.0, (1, 3, 5): 0.0, (1, 3, 6): 0.0, (1, 4, 1): 0.0, (1, 4, 2): 0.0, (1, 4, 3): 0.0, (1, 4, 4): 0.0, (1, 4, 5): 0.0, (1, 4, 6): 0.0, (2, 1, 1): 0.0, (2, 1, 2): 0.0, (2, 1, 3): 0.0, (2, 1, 4): 0.0, (2, 1, 5): 0.0, (2, 1, 6): 1.0, (2, 2, 1): 1.0, (2, 2, 2): 0.0, (2, 2, 3): 0.0, (2, 2, 4): 0.0, (2, 2, 5): 0.0, (2, 2, 6): 0.0, (2, 3, 1): 1.0, (2, 3, 2): 0.0, (2, 3, 3): 0.0, (2, 3, 4): 0.0, (2, 3, 5): 0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): 0.0, (2, 4, 3): 0.0, (2, 4, 4): 0.0, (2, 4, 5): 0.0, (2, 4, 6): 0.0, (3, 1, 1): 0.0, (3, 1, 2): 0.0, (3, 1, 3): 0.0, (3, 1, 4): 1.0, (3, 1, 5): 0.0, (3, 1, 6): 0.0, (3, 2, 1): 0.0, (3, 2, 2): 1.0, (3, 2, 3): 0.0, (3, 2, 4): 0.0, (3, 2, 5): 0.0, (3, 2, 6): 0.0, (3, 3, 1): 0.0, (3, 3, 2): 0.0, (3, 3, 3): 0.0, (3, 3, 4): 0.0, (3, 3, 5): 0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): 0.0, (3, 4, 3): 0.0, (3, 4, 4): 0.0, (3, 4, 5): 0.0, (3, 4, 6): 0.0, (4, 1, 1): 0.0, (4, 1, 2): 0.0, (4, 1, 3): 0.0, (4, 1, 4): 0.0, (4, 1, 5): 0.0, (4, 1, 6): 1.0, (4, 2, 1): 0.0, (4, 2, 2): 1.0, (4, 2, 3): 0.0, (4, 2, 4): 0.0, (4, 2, 5): 0.0, (4, 2, 6): 0.0, (4, 3, 1): 0.0, (4, 3, 2): 1.0, (4, 3, 3): 0.0, (4, 3, 4): 0.0, (4, 3, 5): 0.0, (4, 3, 6): 0.0, (4, 4, 1): 1.0, (4, 4, 2): 0.0, (4, 4, 3): 0.0, (4, 4, 4): 0.0, (4, 4, 5): 0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.0\n",
      "[[0 0 0 1]\n",
      " [3 1 0 2]\n",
      " [5 1 2 2]\n",
      " [5 6 4 6]]\n",
      "528 528\n",
      "Presolve removed 24 rows and 8 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 84 rows, 13090 columns, 1608 nonzeros\n",
      "Variable types: 13002 continuous, 88 integer (88 binary)\n",
      "{(1, 1, 1): -0.0, (1, 1, 2): 1.0, (1, 1, 3): -0.0, (1, 1, 4): -0.0, (1, 1, 5): -0.0, (1, 1, 6): -0.0, (1, 2, 1): -0.0, (1, 2, 2): 1.0, (1, 2, 3): -0.0, (1, 2, 4): -0.0, (1, 2, 5): -0.0, (1, 2, 6): -0.0, (1, 3, 1): -0.0, (1, 3, 2): 1.0, (1, 3, 3): -0.0, (1, 3, 4): -0.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): -0.0, (1, 4, 2): -0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): -0.0, (2, 1, 2): -0.0, (2, 1, 3): 1.0, (2, 1, 4): -0.0, (2, 1, 5): -0.0, (2, 1, 6): -0.0, (2, 2, 1): 1.0, (2, 2, 2): -0.0, (2, 2, 3): -0.0, (2, 2, 4): -0.0, (2, 2, 5): -0.0, (2, 2, 6): -0.0, (2, 3, 1): 1.0, (2, 3, 2): -0.0, (2, 3, 3): -0.0, (2, 3, 4): -0.0, (2, 3, 5): -0.0, (2, 3, 6): 0.0, (2, 4, 1): -0.0, (2, 4, 2): -0.0, (2, 4, 3): -0.0, (2, 4, 4): -0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): -0.0, (3, 1, 3): -0.0, (3, 1, 4): 1.0, (3, 1, 5): -0.0, (3, 1, 6): -0.0, (3, 2, 1): 1.0, (3, 2, 2): -0.0, (3, 2, 3): -0.0, (3, 2, 4): -0.0, (3, 2, 5): -0.0, (3, 2, 6): -0.0, (3, 3, 1): -0.0, (3, 3, 2): -0.0, (3, 3, 3): -0.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): -0.0, (3, 4, 2): -0.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): -0.0, (4, 1, 3): -0.0, (4, 1, 4): -0.0, (4, 1, 5): -0.0, (4, 1, 6): 1.0, (4, 2, 1): -0.0, (4, 2, 2): -0.0, (4, 2, 3): -0.0, (4, 2, 4): -0.0, (4, 2, 5): -0.0, (4, 2, 6): 1.0, (4, 3, 1): -0.0, (4, 3, 2): -0.0, (4, 3, 3): -0.0, (4, 3, 4): -0.0, (4, 3, 5): 1.0, (4, 3, 6): 0.0, (4, 4, 1): -0.0, (4, 4, 2): -0.0, (4, 4, 3): -0.0, (4, 4, 4): -0.0, (4, 4, 5): 1.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.0\n",
      "[[0 0 0 5]\n",
      " [2 1 0 5]\n",
      " [2 1 1 6]\n",
      " [2 3 4 6]]\n",
      "356 721\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.200000e+01   0.000000e+00      9s\n",
      "     915    2.6764893e-05   3.267632e+03   0.000000e+00     10s\n",
      "    1287    0.0000000e+00   0.000000e+00   0.000000e+00     11s\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 1287 iterations, 2.39 seconds (4.38 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   10          -    0.00000      -     -   12s\n",
      "{(1, 1, 1): 0.0, (1, 1, 2): 1.0, (1, 1, 3): 0.0, (1, 1, 4): 0.0, (1, 1, 5): 0.0, (1, 1, 6): 0.0, (1, 2, 1): 0.0, (1, 2, 2): 1.0, (1, 2, 3): 0.0, (1, 2, 4): 0.0, (1, 2, 5): 0.0, (1, 2, 6): 0.0, (1, 3, 1): 0.0, (1, 3, 2): 1.0, (1, 3, 3): 0.0, (1, 3, 4): 0.0, (1, 3, 5): 0.0, (1, 3, 6): 0.0, (1, 4, 1): 0.0, (1, 4, 2): 0.0, (1, 4, 3): 0.0, (1, 4, 4): 0.0, (1, 4, 5): 0.0, (1, 4, 6): 0.0, (2, 1, 1): 0.0, (2, 1, 2): 0.0, (2, 1, 3): 0.0, (2, 1, 4): 0.0, (2, 1, 5): 0.0, (2, 1, 6): 1.0, (2, 2, 1): 0.0, (2, 2, 2): 0.0, (2, 2, 3): 0.0, (2, 2, 4): 0.0, (2, 2, 5): 0.0, (2, 2, 6): 1.0, (2, 3, 1): 0.0, (2, 3, 2): 0.0, (2, 3, 3): 0.0, (2, 3, 4): 0.0, (2, 3, 5): 0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): 0.0, (2, 4, 3): 0.0, (2, 4, 4): 0.0, (2, 4, 5): 0.0, (2, 4, 6): 0.0, (3, 1, 1): 0.0, (3, 1, 2): 0.0, (3, 1, 3): 0.0, (3, 1, 4): 1.0, (3, 1, 5): 0.0, (3, 1, 6): 0.0, (3, 2, 1): 0.0, (3, 2, 2): 0.0, (3, 2, 3): 1.0, (3, 2, 4): 0.0, (3, 2, 5): 0.0, (3, 2, 6): 0.0, (3, 3, 1): 1.0, (3, 3, 2): 0.0, (3, 3, 3): 0.0, (3, 3, 4): 0.0, (3, 3, 5): 0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): 0.0, (3, 4, 3): 0.0, (3, 4, 4): 0.0, (3, 4, 5): 0.0, (3, 4, 6): 0.0, (4, 1, 1): 0.0, (4, 1, 2): 0.0, (4, 1, 3): 0.0, (4, 1, 4): 0.0, (4, 1, 5): 1.0, (4, 1, 6): 0.0, (4, 2, 1): 0.0, (4, 2, 2): 0.0, (4, 2, 3): 0.0, (4, 2, 4): 0.0, (4, 2, 5): 1.0, (4, 2, 6): 0.0, (4, 3, 1): 1.0, (4, 3, 2): 0.0, (4, 3, 3): 0.0, (4, 3, 4): 0.0, (4, 3, 5): 0.0, (4, 3, 6): 0.0, (4, 4, 1): 1.0, (4, 4, 2): 0.0, (4, 4, 3): 0.0, (4, 4, 4): 0.0, (4, 4, 5): 0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.3342696629213471\n",
      "[[0 0 0 1]\n",
      " [2 0 1 1]\n",
      " [2 6 3 5]\n",
      " [2 6 4 5]]\n",
      "410 790\n",
      "     0     0    0.00000    0   10          -    0.00000      -     -   18s\n",
      "{(1, 1, 1): 0.0, (1, 1, 2): 1.0, (1, 1, 3): 0.0, (1, 1, 4): 0.0, (1, 1, 5): 0.0, (1, 1, 6): 0.0, (1, 2, 1): 0.0, (1, 2, 2): 1.0, (1, 2, 3): 0.0, (1, 2, 4): 0.0, (1, 2, 5): 0.0, (1, 2, 6): 0.0, (1, 3, 1): 0.0, (1, 3, 2): 1.0, (1, 3, 3): 0.0, (1, 3, 4): 0.0, (1, 3, 5): 0.0, (1, 3, 6): 0.0, (1, 4, 1): 0.0, (1, 4, 2): 0.0, (1, 4, 3): 0.0, (1, 4, 4): 0.0, (1, 4, 5): 0.0, (1, 4, 6): 0.0, (2, 1, 1): 0.0, (2, 1, 2): 0.0, (2, 1, 3): 0.0, (2, 1, 4): 0.0, (2, 1, 5): 0.0, (2, 1, 6): 1.0, (2, 2, 1): 0.0, (2, 2, 2): 0.0, (2, 2, 3): 0.0, (2, 2, 4): 0.0, (2, 2, 5): 0.0, (2, 2, 6): 1.0, (2, 3, 1): 0.0, (2, 3, 2): 0.0, (2, 3, 3): 0.0, (2, 3, 4): 0.0, (2, 3, 5): 0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): 0.0, (2, 4, 3): 0.0, (2, 4, 4): 0.0, (2, 4, 5): 0.0, (2, 4, 6): 0.0, (3, 1, 1): 0.0, (3, 1, 2): 0.0, (3, 1, 3): 0.0, (3, 1, 4): 1.0, (3, 1, 5): 0.0, (3, 1, 6): 0.0, (3, 2, 1): 0.0, (3, 2, 2): 0.0, (3, 2, 3): 1.0, (3, 2, 4): 0.0, (3, 2, 5): 0.0, (3, 2, 6): 0.0, (3, 3, 1): 1.0, (3, 3, 2): 0.0, (3, 3, 3): 0.0, (3, 3, 4): 0.0, (3, 3, 5): 0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): 0.0, (3, 4, 3): 0.0, (3, 4, 4): 0.0, (3, 4, 5): 0.0, (3, 4, 6): 0.0, (4, 1, 1): 0.0, (4, 1, 2): 0.0, (4, 1, 3): 0.0, (4, 1, 4): 0.0, (4, 1, 5): 1.0, (4, 1, 6): 0.0, (4, 2, 1): 0.0, (4, 2, 2): 0.0, (4, 2, 3): 0.0, (4, 2, 4): 0.0, (4, 2, 5): 1.0, (4, 2, 6): 0.0, (4, 3, 1): 1.0, (4, 3, 2): 0.0, (4, 3, 3): 0.0, (4, 3, 4): 0.0, (4, 3, 5): 0.0, (4, 3, 6): 0.0, (4, 4, 1): 1.0, (4, 4, 2): 0.0, (4, 4, 3): 0.0, (4, 4, 4): 0.0, (4, 4, 5): 0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.41951219512195076\n",
      "[[0 0 0 1]\n",
      " [2 0 1 1]\n",
      " [2 6 3 5]\n",
      " [2 6 4 5]]\n",
      "410 790\n",
      "H    0     0                       0.4195122    0.00000   100%     -   23s\n",
      "     0     0    0.00000    0   10    0.41951    0.00000   100%     -   26s\n",
      "     0     2    0.00000    0   10    0.41951    0.00000   100%     -   31s\n",
      "     1     4    0.00000    1   19    0.41951    0.00000   100%   256   38s\n",
      "{(1, 1, 1): 0.0, (1, 1, 2): -0.0, (1, 1, 3): -0.0, (1, 1, 4): -0.0, (1, 1, 5): 1.0, (1, 1, 6): -0.0, (1, 2, 1): 1.0, (1, 2, 2): -0.0, (1, 2, 3): -0.0, (1, 2, 4): -0.0, (1, 2, 5): -0.0, (1, 2, 6): 0.0, (1, 3, 1): 1.0, (1, 3, 2): -0.0, (1, 3, 3): -0.0, (1, 3, 4): -0.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): 1.0, (1, 4, 2): -0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): -0.0, (2, 1, 2): 0.0, (2, 1, 3): -0.0, (2, 1, 4): -0.0, (2, 1, 5): -0.0, (2, 1, 6): 1.0, (2, 2, 1): 0.0, (2, 2, 2): -0.0, (2, 2, 3): -0.0, (2, 2, 4): -0.0, (2, 2, 5): -0.0, (2, 2, 6): 1.0, (2, 3, 1): -0.0, (2, 3, 2): -0.0, (2, 3, 3): -0.0, (2, 3, 4): -0.0, (2, 3, 5): 1.0, (2, 3, 6): 0.0, (2, 4, 1): -0.0, (2, 4, 2): 1.0, (2, 4, 3): -0.0, (2, 4, 4): -0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): 0.0, (3, 1, 3): -0.0, (3, 1, 4): 1.0, (3, 1, 5): -0.0, (3, 1, 6): -0.0, (3, 2, 1): 0.0, (3, 2, 2): 1.0, (3, 2, 3): -0.0, (3, 2, 4): -0.0, (3, 2, 5): 0.0, (3, 2, 6): -0.0, (3, 3, 1): 0.0, (3, 3, 2): 1.0, (3, 3, 3): -0.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): -0.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): -0.0, (4, 1, 3): 1.0, (4, 1, 4): -0.0, (4, 1, 5): 0.0, (4, 1, 6): -0.0, (4, 2, 1): -0.0, (4, 2, 2): -0.0, (4, 2, 3): 0.0, (4, 2, 4): -0.0, (4, 2, 5): 0.0, (4, 2, 6): -0.0, (4, 3, 1): 0.0, (4, 3, 2): -0.0, (4, 3, 3): 0.0, (4, 3, 4): 0.0, (4, 3, 5): -0.0, (4, 3, 6): 0.0, (4, 4, 1): -0.0, (4, 4, 2): -0.0, (4, 4, 3): -0.0, (4, 4, 4): -0.0, (4, 4, 5): -0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.417073170730877\n",
      "[[1 2 0 0]\n",
      " [1 5 2 0]\n",
      " [1 6 2 0]\n",
      " [5 6 4 3]]\n",
      "355 790\n",
      "H    3     6                       0.4170732    0.00000   100%   474   59s\n",
      "{(1, 1, 1): -0.0, (1, 1, 2): -0.0, (1, 1, 3): -0.0, (1, 1, 4): -0.0, (1, 1, 5): 0.0, (1, 1, 6): 1.0, (1, 2, 1): -0.0, (1, 2, 2): -0.0, (1, 2, 3): 1.0, (1, 2, 4): -0.0, (1, 2, 5): -0.0, (1, 2, 6): -0.0, (1, 3, 1): -0.0, (1, 3, 2): -0.0, (1, 3, 3): 0.0, (1, 3, 4): -0.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): -0.0, (1, 4, 2): -0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): -0.0, (2, 1, 2): -0.0, (2, 1, 3): -0.0, (2, 1, 4): 0.0, (2, 1, 5): 0.0, (2, 1, 6): 1.0, (2, 2, 1): 0.0, (2, 2, 2): 1.0, (2, 2, 3): -0.0, (2, 2, 4): 0.0, (2, 2, 5): -0.0, (2, 2, 6): -0.0, (2, 3, 1): 0.0, (2, 3, 2): -0.0, (2, 3, 3): -0.0, (2, 3, 4): -0.0, (2, 3, 5): -0.0, (2, 3, 6): 0.0, (2, 4, 1): -0.0, (2, 4, 2): -0.0, (2, 4, 3): -0.0, (2, 4, 4): -0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): 0.0, (3, 1, 3): -0.0, (3, 1, 4): -0.0, (3, 1, 5): 1.0, (3, 1, 6): 0.0, (3, 2, 1): -0.0, (3, 2, 2): 0.0, (3, 2, 3): -0.0, (3, 2, 4): -0.0, (3, 2, 5): 1.0, (3, 2, 6): 0.0, (3, 3, 1): -0.0, (3, 3, 2): 1.0, (3, 3, 3): -0.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): 1.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): -0.0, (4, 1, 3): -0.0, (4, 1, 4): 1.0, (4, 1, 5): -0.0, (4, 1, 6): -0.0, (4, 2, 1): 1.0, (4, 2, 2): 0.0, (4, 2, 3): -0.0, (4, 2, 4): 0.0, (4, 2, 5): 0.0, (4, 2, 6): 0.0, (4, 3, 1): 1.0, (4, 3, 2): -0.0, (4, 3, 3): -0.0, (4, 3, 4): 0.0, (4, 3, 5): -0.0, (4, 3, 6): 0.0, (4, 4, 1): 1.0, (4, 4, 2): -0.0, (4, 4, 3): -0.0, (4, 4, 4): 0.0, (4, 4, 5): -0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.17317073170722025\n",
      "[[0 0 2 1]\n",
      " [0 0 2 1]\n",
      " [3 2 5 1]\n",
      " [6 6 5 4]]\n",
      "146 790\n",
      "     5     6    0.15122    2   15    0.41707    0.00000   100%   554   67s\n",
      "     7    10    0.00751    3   33    0.41707    0.00000   100%   691   83s\n",
      "    11    14    0.01408    4   29    0.41707    0.00751  98.2%   624   87s\n",
      "    15    18    0.00751    4   34    0.41707    0.00751  98.2%   510  102s\n",
      "{(1, 1, 1): -0.0, (1, 1, 2): -0.0, (1, 1, 3): -0.0, (1, 1, 4): -0.0, (1, 1, 5): 1.0, (1, 1, 6): -0.0, (1, 2, 1): 1.0, (1, 2, 2): -0.0, (1, 2, 3): -0.0, (1, 2, 4): -0.0, (1, 2, 5): -0.0, (1, 2, 6): -0.0, (1, 3, 1): 1.0, (1, 3, 2): 0.0, (1, 3, 3): -0.0, (1, 3, 4): 0.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): 1.0, (1, 4, 2): 0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): 0.0, (2, 1, 2): -0.0, (2, 1, 3): -0.0, (2, 1, 4): 1.0, (2, 1, 5): -0.0, (2, 1, 6): -0.0, (2, 2, 1): 0.0, (2, 2, 2): 0.0, (2, 2, 3): -0.0, (2, 2, 4): -0.0, (2, 2, 5): -0.0, (2, 2, 6): -0.0, (2, 3, 1): 0.0, (2, 3, 2): -0.0, (2, 3, 3): -0.0, (2, 3, 4): 0.0, (2, 3, 5): -0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): -0.0, (2, 4, 3): -0.0, (2, 4, 4): -0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): -0.0, (3, 1, 3): 0.0, (3, 1, 4): -0.0, (3, 1, 5): 0.0, (3, 1, 6): 1.0, (3, 2, 1): -0.0, (3, 2, 2): -0.0, (3, 2, 3): -0.0, (3, 2, 4): -0.0, (3, 2, 5): 0.0, (3, 2, 6): 1.0, (3, 3, 1): -0.0, (3, 3, 2): -0.0, (3, 3, 3): 1.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): -0.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): 0.0, (4, 1, 3): -0.0, (4, 1, 4): 0.0, (4, 1, 5): 1.0, (4, 1, 6): 0.0, (4, 2, 1): -0.0, (4, 2, 2): 1.0, (4, 2, 3): -0.0, (4, 2, 4): 0.0, (4, 2, 5): -0.0, (4, 2, 6): -0.0, (4, 3, 1): -0.0, (4, 3, 2): 1.0, (4, 3, 3): -0.0, (4, 3, 4): -0.0, (4, 3, 5): -0.0, (4, 3, 6): 0.0, (4, 4, 1): -0.0, (4, 4, 2): 1.0, (4, 4, 3): -0.0, (4, 4, 4): -0.0, (4, 4, 5): -0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.16585365853654607\n",
      "[[1 0 0 2]\n",
      " [1 0 3 2]\n",
      " [1 0 6 2]\n",
      " [5 4 6 5]]\n",
      "140 790\n",
      "{(1, 1, 1): -0.0, (1, 1, 2): -0.0, (1, 1, 3): -0.0, (1, 1, 4): 0.0, (1, 1, 5): 1.0, (1, 1, 6): -0.0, (1, 2, 1): -0.0, (1, 2, 2): 0.0, (1, 2, 3): -0.0, (1, 2, 4): -0.0, (1, 2, 5): 1.0, (1, 2, 6): 0.0, (1, 3, 1): -0.0, (1, 3, 2): 0.0, (1, 3, 3): -0.0, (1, 3, 4): 1.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): 1.0, (1, 4, 2): -0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): -0.0, (2, 1, 2): -0.0, (2, 1, 3): -0.0, (2, 1, 4): 0.0, (2, 1, 5): -0.0, (2, 1, 6): 1.0, (2, 2, 1): 0.0, (2, 2, 2): -0.0, (2, 2, 3): -0.0, (2, 2, 4): 0.0, (2, 2, 5): -0.0, (2, 2, 6): -0.0, (2, 3, 1): 0.0, (2, 3, 2): -0.0, (2, 3, 3): -0.0, (2, 3, 4): -0.0, (2, 3, 5): -0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): 0.0, (2, 4, 3): -0.0, (2, 4, 4): -0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): 0.0, (3, 1, 3): -0.0, (3, 1, 4): -0.0, (3, 1, 5): -0.0, (3, 1, 6): 1.0, (3, 2, 1): -0.0, (3, 2, 2): 1.0, (3, 2, 3): -0.0, (3, 2, 4): -0.0, (3, 2, 5): -0.0, (3, 2, 6): -0.0, (3, 3, 1): -0.0, (3, 3, 2): 1.0, (3, 3, 3): -0.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): -0.0, (3, 4, 2): 1.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): -0.0, (4, 1, 3): 1.0, (4, 1, 4): -0.0, (4, 1, 5): -0.0, (4, 1, 6): 0.0, (4, 2, 1): 1.0, (4, 2, 2): -0.0, (4, 2, 3): -0.0, (4, 2, 4): -0.0, (4, 2, 5): -0.0, (4, 2, 6): -0.0, (4, 3, 1): 1.0, (4, 3, 2): -0.0, (4, 3, 3): -0.0, (4, 3, 4): -0.0, (4, 3, 5): -0.0, (4, 3, 6): 0.0, (4, 4, 1): -0.0, (4, 4, 2): 0.0, (4, 4, 3): -0.0, (4, 4, 4): -0.0, (4, 4, 5): -0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.26794258373157237\n",
      "[[1 0 2 0]\n",
      " [4 0 2 1]\n",
      " [5 0 2 1]\n",
      " [5 6 6 3]]\n",
      "367 894\n",
      "    18    18    0.15122    4   26    0.41707    0.00751  98.2%   448  124s\n",
      "    19    22    0.00892    5   37    0.41707    0.00751  98.2%   472  130s\n",
      "    23    25    0.01639    6   31    0.41707    0.00751  98.2%   464  135s\n",
      "{(1, 1, 1): -0.0, (1, 1, 2): 0.0, (1, 1, 3): -0.0, (1, 1, 4): 0.0, (1, 1, 5): 1.0, (1, 1, 6): -0.0, (1, 2, 1): -0.0, (1, 2, 2): -0.0, (1, 2, 3): -0.0, (1, 2, 4): -0.0, (1, 2, 5): 1.0, (1, 2, 6): -0.0, (1, 3, 1): 1.0, (1, 3, 2): -0.0, (1, 3, 3): -0.0, (1, 3, 4): 0.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): 1.0, (1, 4, 2): -0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): 0.0, (2, 1, 2): -0.0, (2, 1, 3): -0.0, (2, 1, 4): 1.0, (2, 1, 5): 0.0, (2, 1, 6): 0.0, (2, 2, 1): 1.0, (2, 2, 2): 0.0, (2, 2, 3): -0.0, (2, 2, 4): -0.0, (2, 2, 5): -0.0, (2, 2, 6): 0.0, (2, 3, 1): 0.0, (2, 3, 2): 0.0, (2, 3, 3): -0.0, (2, 3, 4): 0.0, (2, 3, 5): -0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): -0.0, (2, 4, 3): -0.0, (2, 4, 4): 0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): -0.0, (3, 1, 3): 0.0, (3, 1, 4): 0.0, (3, 1, 5): 0.0, (3, 1, 6): 1.0, (3, 2, 1): -0.0, (3, 2, 2): -0.0, (3, 2, 3): -0.0, (3, 2, 4): -0.0, (3, 2, 5): -0.0, (3, 2, 6): 1.0, (3, 3, 1): -0.0, (3, 3, 2): -0.0, (3, 3, 3): 1.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): -0.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): 1.0, (4, 1, 3): -0.0, (4, 1, 4): 0.0, (4, 1, 5): -0.0, (4, 1, 6): 0.0, (4, 2, 1): 0.0, (4, 2, 2): 1.0, (4, 2, 3): -0.0, (4, 2, 4): 0.0, (4, 2, 5): -0.0, (4, 2, 6): -0.0, (4, 3, 1): -0.0, (4, 3, 2): 1.0, (4, 3, 3): -0.0, (4, 3, 4): -0.0, (4, 3, 5): -0.0, (4, 3, 6): 0.0, (4, 4, 1): 0.0, (4, 4, 2): -0.0, (4, 4, 3): -0.0, (4, 4, 4): 0.0, (4, 4, 5): -0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.15185185185185174\n",
      "[[1 0 0 0]\n",
      " [1 0 3 2]\n",
      " [5 1 6 2]\n",
      " [5 4 6 2]]\n",
      "142 894\n",
      "*   25    25               6       0.1548148    0.00751  95.1%   430  149s\n",
      "    28    26    0.01639    6   32    0.15481    0.00751  95.1%   470  176s\n",
      "    33    22    0.02817    7   19    0.15481    0.00751  95.1%   448  181s\n",
      "    39    22    0.01639    7   29    0.15481    0.00751  95.1%   397  186s\n",
      "    45    25    0.02465    8   28    0.15481    0.00751  95.1%   376  195s\n",
      "{(1, 1, 1): -0.0, (1, 1, 2): -0.0, (1, 1, 3): 1.0, (1, 1, 4): -0.0, (1, 1, 5): -0.0, (1, 1, 6): 0.0, (1, 2, 1): -0.0, (1, 2, 2): -0.0, (1, 2, 3): -0.0, (1, 2, 4): -0.0, (1, 2, 5): -0.0, (1, 2, 6): -0.0, (1, 3, 1): -0.0, (1, 3, 2): -0.0, (1, 3, 3): -0.0, (1, 3, 4): -0.0, (1, 3, 5): -0.0, (1, 3, 6): 0.0, (1, 4, 1): 0.0, (1, 4, 2): -0.0, (1, 4, 3): -0.0, (1, 4, 4): -0.0, (1, 4, 5): -0.0, (1, 4, 6): 0.0, (2, 1, 1): -0.0, (2, 1, 2): -0.0, (2, 1, 3): -0.0, (2, 1, 4): -0.0, (2, 1, 5): 1.0, (2, 1, 6): -0.0, (2, 2, 1): 0.0, (2, 2, 2): -0.0, (2, 2, 3): 0.0, (2, 2, 4): -0.0, (2, 2, 5): 1.0, (2, 2, 6): -0.0, (2, 3, 1): 0.0, (2, 3, 2): 1.0, (2, 3, 3): -0.0, (2, 3, 4): -0.0, (2, 3, 5): -0.0, (2, 3, 6): 0.0, (2, 4, 1): 0.0, (2, 4, 2): 1.0, (2, 4, 3): -0.0, (2, 4, 4): -0.0, (2, 4, 5): -0.0, (2, 4, 6): 0.0, (3, 1, 1): -0.0, (3, 1, 2): -0.0, (3, 1, 3): -0.0, (3, 1, 4): -0.0, (3, 1, 5): 0.0, (3, 1, 6): 1.0, (3, 2, 1): -0.0, (3, 2, 2): -0.0, (3, 2, 3): -0.0, (3, 2, 4): 0.0, (3, 2, 5): 0.0, (3, 2, 6): 1.0, (3, 3, 1): -0.0, (3, 3, 2): 1.0, (3, 3, 3): -0.0, (3, 3, 4): -0.0, (3, 3, 5): -0.0, (3, 3, 6): 0.0, (3, 4, 1): 0.0, (3, 4, 2): 0.0, (3, 4, 3): -0.0, (3, 4, 4): -0.0, (3, 4, 5): -0.0, (3, 4, 6): 0.0, (4, 1, 1): -0.0, (4, 1, 2): -0.0, (4, 1, 3): -0.0, (4, 1, 4): 1.0, (4, 1, 5): 0.0, (4, 1, 6): -0.0, (4, 2, 1): 1.0, (4, 2, 2): -0.0, (4, 2, 3): -0.0, (4, 2, 4): -0.0, (4, 2, 5): 0.0, (4, 2, 6): -0.0, (4, 3, 1): 1.0, (4, 3, 2): -0.0, (4, 3, 3): -0.0, (4, 3, 4): -0.0, (4, 3, 5): 0.0, (4, 3, 6): 0.0, (4, 4, 1): 1.0, (4, 4, 2): -0.0, (4, 4, 3): -0.0, (4, 4, 4): -0.0, (4, 4, 5): -0.0, (4, 4, 6): 0.0}\n",
      "alpha_tmp 0.02790697674418602\n",
      "[[0 2 0 1]\n",
      " [0 2 2 1]\n",
      " [0 5 6 1]\n",
      " [3 5 6 4]]\n",
      "12 894\n",
      "*   48    25              12       0.0362791    0.00751  79.3%   354  204s\n",
      "    52    29    0.02817    9   20    0.03628    0.00751  79.3%   351  207s\n",
      "    58    33    0.02817   10   10    0.03628    0.00751  79.3%   332  215s\n",
      "    82    31     cutoff   13         0.03628    0.01639  54.8%   258  221s\n",
      "    98    36    0.02817    6   10    0.03628    0.01639  54.8%   236  226s\n",
      "   127    29    0.02817    8   10    0.03628    0.01639  54.8%   196  232s\n",
      "   147    30 infeasible    9         0.03628    0.01639  54.8%   175  239s\n",
      "   158    32    0.02817    7   14    0.03628    0.01639  54.8%   175  245s\n",
      "   194    31     cutoff   11         0.03628    0.02817  22.4%   157  252s\n",
      "   212    19     cutoff   11         0.03628    0.02817  22.4%   150  258s\n",
      "   236     8     cutoff    8         0.03628    0.02817  22.4%   142  260s\n",
      "\n",
      "Cutting planes:\n",
      "  Lazy constraints: 214444\n",
      "\n",
      "Explored 273 nodes (37308 simplex iterations) in 264.58 seconds (160.79 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 0.0362791 0.154815 0.417073 0.419512 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.627906976744e-02, best bound 3.627906976744e-02, gap 0.0000%\n",
      "\n",
      "User-callback calls 2262, time in user-callback 81.00 sec\n"
     ]
    }
   ],
   "source": [
    "size=1000\n",
    "size_=10000\n",
    "beta=0.75\n",
    "inst=[4,4,[3,3,1,1,2,2]]\n",
    "pcvar=[]\n",
    "import numpy as np\n",
    "# mean=np.arange(1,ship_num+1)\n",
    "mean=np.array([1,1.5,4,4.5,5,5.6])\n",
    "covl=[1,1,1.5,1,1,1.5]\n",
    "# a=list(a)\n",
    "# a=random.sample(a,ship_num)\n",
    "# mean=np.sort(a)\n",
    "cov=np.zeros((len(inst[2]),len(inst[2])))\n",
    "for i in range(len(inst[2])):\n",
    "    for j in range(len(inst[2])):\n",
    "        if i==j:\n",
    "            cov[i][i]=covl[1]\n",
    "for i in range(len(inst[2])):\n",
    "    for j in range(len(inst[2])):\n",
    "        if i!=j:\n",
    "            cov[i][j]=0\n",
    "\n",
    "\n",
    "OC=[]\n",
    "EPS=0.1\n",
    "a=0\n",
    "UB=1000\n",
    "LB=0\n",
    "UB_k=[]\n",
    "zk=[]\n",
    "aaa=[]\n",
    "# while UB-LB>=EPS:\n",
    "#     print(\"UB=\",UB)\n",
    "#     print(\"LB=\",LB)\n",
    "#     print(\"UB-LB=\",UB-LB)\n",
    "#     print(\"LEN=\",len(OC))\n",
    "#     model=CuttingPlaneAlgorithm(len(inst[2]),inst[0],inst[1],inst[2],size,size_,beta,mean,cov,OC,zk)\n",
    "#     zk,OC,penalty=model.solve()\n",
    "#     n=0\n",
    "#     while n\n",
    "#         n+=1\n",
    "#     tau=n\n",
    "#     N_sigma=np.sort(penalty)\n",
    "#     alpha_=N_sigma[tau-1]\n",
    "\n",
    "#     UB=((tau/size-beta)*alpha_+sum(N_sigma[tau:]))/((1-beta)*size)\n",
    "#     UB_k.append(UB)\n",
    "#     UB=min(UB_k)\n",
    "#     # for b in zk:\n",
    "#     #     if not O[b] in OC:\n",
    "#     #         OC.append(O[b])\n",
    "#     a+=1\n",
    "#     # print(OC)\n",
    "# print(\"finish!!\")\n",
    "model=CuttingPlaneAlgorithm(len(inst[2]),inst[0],inst[1],inst[2],size,size_,0.75,mean,cov,OC,zk,aaa)\n",
    "model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036279069767441836\n"
     ]
    }
   ],
   "source": [
    "b=model.get_optimal_val()\n",
    "print(b)\n",
    "x_opt,c_opt,alpha_opt,u_opt=model.get_optimal_sol()\n",
    "\n",
    "result=model.get_result(x_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 1]\n",
      " [0 2 2 1]\n",
      " [0 5 6 1]\n",
      " [3 5 6 4]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust(ship_num,stack_num,height,n,Gamma,size_,mean,cov):\n",
    "  # nと初期配置を変更しなければいけない\n",
    "  num=sum(n)\n",
    "\n",
    "  import numpy as np\n",
    "\n",
    "  O1=[i+1 for i in range(ship_num)]\n",
    "\n",
    "  Q=[i+1 for i in range(stack_num)]\n",
    "  L=[i+1 for i in range(height)]\n",
    "  P=[i+1 for i in range(ship_num)]\n",
    "  I=[i+1 for i in range(num)]\n",
    "  f=stack_num*height-len(I)\n",
    "  a=1\n",
    "  gamma=[]\n",
    "  for i in n:\n",
    "      for j in range(1,i+1):\n",
    "          gamma.append(a)\n",
    "      a+=1\n",
    "  \n",
    "  m=Model(\"BI\")\n",
    "\n",
    "  # 変数の定義\n",
    "  alpha,beta={},{}\n",
    "  for i in I:\n",
    "      for q in Q:\n",
    "          alpha[i,q]=m.addVar(vtype=\"B\")\n",
    "          beta[i,q]=m.addVar(vtype=\"B\")\n",
    "  J=[]\n",
    "  for i in I:\n",
    "      J.append([])\n",
    "      for j in I:\n",
    "          if gamma[i-1]<gamma[j-1]:\n",
    "              if gamma[j-1]-gamma[i-1]<=Gamma:\n",
    "                  J[i-1].append(j)\n",
    "\n",
    "  for q in Q:\n",
    "      m.addConstr(quicksum((alpha[i,q]+beta[i,q]) for i in I)<=len(L))\n",
    "\n",
    "  for i in I:\n",
    "      m.addConstr(quicksum((alpha[i,q]+beta[i,q]) for q in Q)==1)\n",
    "\n",
    "  for i in I:\n",
    "      for j in J[i-1]:\n",
    "          for q in Q:\n",
    "              m.addConstr(alpha[i,q]+alpha[j,q]+beta[j,q]<=1)\n",
    "\n",
    "  m.setObjective(quicksum(beta[i,q] for i in I for q in Q))\n",
    "\n",
    "  if f>=height:\n",
    "      m.optimize()\n",
    "\n",
    "  EPS=1.e-6\n",
    "\n",
    "  if m.Status == GRB.OPTIMAL:\n",
    "      print(\"====================================================\")\n",
    "\n",
    "      EPS=1.e-6\n",
    "      a=[]\n",
    "      for q in Q:\n",
    "          a.append([])\n",
    "      for (i,q) in alpha:\n",
    "          if alpha[i,q].X>EPS:\n",
    "              a[q-1].append(gamma[i-1])\n",
    "      \n",
    "      for (i,q) in beta:\n",
    "          if beta[i,q].X>EPS:\n",
    "              a[q-1].append(gamma[i-1])\n",
    "\n",
    "      for q in Q:\n",
    "          a[q-1]=sorted(a[q-1],reverse=True)\n",
    "\n",
    "      global result_r\n",
    "      result_r=np.zeros((height,stack_num))\n",
    "      for q in Q:\n",
    "          for i,r in enumerate(a[q-1]):\n",
    "              result_r[height-i-1][q-1]=r\n",
    "          # print(i,r)\n",
    "\n",
    "      result_r=result_r.astype(int)\n",
    "      \n",
    "      print(result_r)\n",
    "      print(\"the objective function\", m.objVal)\n",
    "\n",
    "      from asyncio.constants import SENDFILE_FALLBACK_READBUFFER_SIZE\n",
    "      import random\n",
    "      from random import seed\n",
    "      import numpy as np\n",
    "      from scipy.stats import multivariate_normal\n",
    "\n",
    "      np.random.seed()\n",
    "      data_1 = np.random.multivariate_normal(mean, cov, size=size_)\n",
    "\n",
    "      O_=np.argsort(data_1)\n",
    "      O_=O_+np.ones((size_,ship_num)).astype(int)\n",
    "      OR=O_.tolist()\n",
    "\n",
    "\n",
    "      global penalty_r\n",
    "      penalty_r=[]\n",
    "      for k in OR:\n",
    "          O=k\n",
    "          a=0\n",
    "          for j in range(stack_num):\n",
    "              for i in range(1,height):\n",
    "                  for i_ in range(i+1,height+1):\n",
    "                      if result_r[i-1][j]!=0 and result_r[i_-1][j]!=0:\n",
    "                          if O.index(result_r[i-1][j])>O.index(result_r[i_-1][j]):\n",
    "                              a+=1\n",
    "                              # if Gamma ==2:\n",
    "                                # print(j+1,height-i+1,O)\n",
    "                              # print(\"penalty!\")\n",
    "                              # print(i,i_,j+1,O)\n",
    "                              break\n",
    "          penalty_r.append(a)\n",
    "      \n",
    "      penalty_r=np.sort(penalty_r)\n",
    "      penalty_r=penalty_r[round(0.75*size_):]\n",
    "      # print(penalty_r)\n",
    "\n",
    "      # import matplotlib.pyplot as plt\n",
    "      # plt.boxplot(penalty_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 92 rows, 96 columns and 420 nonzeros\n",
      "Model fingerprint: 0x4674e4c6\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 3.0000000\n",
      "Presolve removed 0 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 92 rows, 88 columns, 388 nonzeros\n",
      "Found heuristic solution: objective 1.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 23 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (23 simplex iterations) in 0.06 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0 1 3 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[2 0 0 0]\n",
      " [2 1 0 1]\n",
      " [2 4 3 1]\n",
      " [5 6 6 5]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 132 rows, 96 columns and 540 nonzeros\n",
      "Model fingerprint: 0xe2d2b478\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 4.0000000\n",
      "Presolve removed 24 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 108 rows, 88 columns, 492 nonzeros\n",
      "Found heuristic solution: objective 1.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 40 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (40 simplex iterations) in 0.06 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0 1 4 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[2 0 0 1]\n",
      " [2 0 0 1]\n",
      " [2 1 3 5]\n",
      " [6 4 6 5]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 176 rows, 96 columns and 672 nonzeros\n",
      "Model fingerprint: 0x0d429557\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 6.0000000\n",
      "Presolve removed 44 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 132 rows, 88 columns, 648 nonzeros\n",
      "Found heuristic solution: objective 2.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 40 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   23    2.00000    0.00000   100%     -    0s\n",
      "H    0     0                       1.0000000    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   23    1.00000    0.00000   100%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Zero half: 2\n",
      "\n",
      "Explored 1 nodes (147 simplex iterations) in 0.09 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1 2 6 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000000000000e+00, best bound 1.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 2 0 1]\n",
      " [0 2 0 1]\n",
      " [5 2 3 1]\n",
      " [5 6 4 6]]\n",
      "the objective function 1.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 224 rows, 96 columns and 816 nonzeros\n",
      "Model fingerprint: 0xae77780b\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 7.0000000\n",
      "Presolve removed 60 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 164 rows, 88 columns, 864 nonzeros\n",
      "Found heuristic solution: objective 2.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 54 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   12    2.00000    1.00000  50.0%     -    0s\n",
      "     0     0    1.00000    0   19    2.00000    1.00000  50.0%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Zero half: 1\n",
      "\n",
      "Explored 1 nodes (126 simplex iterations) in 0.10 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 2 7 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[3 0 0 1]\n",
      " [4 2 0 1]\n",
      " [5 2 0 1]\n",
      " [5 2 6 6]]\n",
      "the objective function 2.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 248 rows, 96 columns and 888 nonzeros\n",
      "Model fingerprint: 0xe8ee5973\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 5.0000000\n",
      "Presolve removed 68 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 180 rows, 88 columns, 992 nonzeros\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "Found heuristic solution: objective 4.0000000\n",
      "\n",
      "Root relaxation: objective 2.000000e+00, 75 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       2.0000000    2.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (75 simplex iterations) in 0.07 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 2 4 5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 3 0 0]\n",
      " [1 4 0 2]\n",
      " [1 5 6 2]\n",
      " [1 5 6 2]]\n",
      "the objective function 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_2 = np.random.multivariate_normal(mean, cov, size=size_)\n",
    "\n",
    "OR_=np.argsort(data_2)\n",
    "OR_=OR_+np.ones((size_,len(inst[2]))).astype(int)\n",
    "OR=OR_.tolist()\n",
    "penalty_cvar=[]\n",
    "for k in OR:\n",
    "    OR2=k\n",
    "    a=0\n",
    "    for j in range(inst[0]):\n",
    "        for i in range(1,inst[1]):\n",
    "            for i_ in range(i+1,inst[1]+1):\n",
    "                if result[i-1][j]!=0 and result[i_-1][j]!=0:\n",
    "                    if OR2.index(result[i-1][j])>OR2.index(result[i_-1][j]):\n",
    "                        # print(j+1,height-i+1,O)\n",
    "                        a+=1\n",
    "                        # print(\"penalty!\")\n",
    "                            # print(i,i_,j+1,O)\n",
    "                        break\n",
    "    penalty_cvar.append(a)\n",
    "penalty_cvar=np.sort(penalty_cvar)\n",
    "penalty_cvar=penalty_cvar[round(0.75*size_):]\n",
    "pcvar=[]\n",
    "pcvar+=list(penalty_cvar)\n",
    "data=(tuple(pcvar),)\n",
    "l=[\"75%-CVaR\"]\n",
    "for g in range(1,6):\n",
    "  prob=[]\n",
    "  ship_num=len(inst[2])\n",
    "  robust(ship_num,inst[0],inst[1],inst[2],g,size_,mean,cov)\n",
    "  prob+=list(penalty_r)\n",
    "#   print(prob)\n",
    "  data+=(tuple(prob),)\n",
    "  l.append(\"Gamma=\"+str(g))\n",
    "  # print(\"data=\",data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(data,labels=l)\n",
    "plt.show()\n",
    "# plt.hist(penalty_cvar,bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 92 rows, 96 columns and 420 nonzeros\n",
      "Model fingerprint: 0x4674e4c6\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 3.0000000\n",
      "Presolve removed 0 rows and 8 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 92 rows, 88 columns, 388 nonzeros\n",
      "Found heuristic solution: objective 1.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 23 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (23 simplex iterations) in 0.05 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0 1 3 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[2 0 0 0]\n",
      " [2 1 0 1]\n",
      " [2 4 3 1]\n",
      " [5 6 6 5]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 132 rows, 96 columns and 540 nonzeros\n",
      "Model fingerprint: 0xe2d2b478\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 4.0000000\n",
      "Presolve removed 24 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 108 rows, 88 columns, 492 nonzeros\n",
      "Found heuristic solution: objective 1.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 40 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.0000000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (40 simplex iterations) in 0.08 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0 1 4 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[2 0 0 1]\n",
      " [2 0 0 1]\n",
      " [2 1 3 5]\n",
      " [6 4 6 5]]\n",
      "the objective function 0.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 176 rows, 96 columns and 672 nonzeros\n",
      "Model fingerprint: 0x0d429557\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 6.0000000\n",
      "Presolve removed 44 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 132 rows, 88 columns, 648 nonzeros\n",
      "Found heuristic solution: objective 2.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 40 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   23    2.00000    0.00000   100%     -    0s\n",
      "H    0     0                       1.0000000    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   23    1.00000    0.00000   100%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Zero half: 2\n",
      "\n",
      "Explored 1 nodes (147 simplex iterations) in 0.15 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1 2 6 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000000000000e+00, best bound 1.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 2 0 1]\n",
      " [0 2 0 1]\n",
      " [5 2 3 1]\n",
      " [5 6 4 6]]\n",
      "the objective function 1.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 224 rows, 96 columns and 816 nonzeros\n",
      "Model fingerprint: 0xae77780b\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 7.0000000\n",
      "Presolve removed 60 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 164 rows, 88 columns, 864 nonzeros\n",
      "Found heuristic solution: objective 2.0000000\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 54 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   12    2.00000    1.00000  50.0%     -    0s\n",
      "     0     0    1.00000    0   19    2.00000    1.00000  50.0%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Zero half: 1\n",
      "\n",
      "Explored 1 nodes (126 simplex iterations) in 0.20 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 2 7 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[3 0 0 1]\n",
      " [4 2 0 1]\n",
      " [5 2 0 1]\n",
      " [5 2 6 6]]\n",
      "the objective function 2.0\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 248 rows, 96 columns and 888 nonzeros\n",
      "Model fingerprint: 0xe8ee5973\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Found heuristic solution: objective 5.0000000\n",
      "Presolve removed 68 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 180 rows, 88 columns, 992 nonzeros\n",
      "Variable types: 0 continuous, 88 integer (88 binary)\n",
      "Found heuristic solution: objective 4.0000000\n",
      "\n",
      "Root relaxation: objective 2.000000e+00, 75 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       2.0000000    2.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (75 simplex iterations) in 0.05 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 2 4 5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "====================================================\n",
      "[[0 3 0 0]\n",
      " [1 4 0 2]\n",
      " [1 5 6 2]\n",
      " [1 5 6 2]]\n",
      "the objective function 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len= 2500\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,3,figsize=(20,10),tight_layout=True)\n",
    "for g in range(1,6):\n",
    "  prob=[]\n",
    "  ship_num=len(inst[2])\n",
    "  robust(ship_num,inst[0],inst[1],inst[2],g,size_,mean,cov)\n",
    "  prob+=list(penalty_r)\n",
    "  # print(prob)\n",
    "  # data+=(tuple(prob),)\n",
    "  # l.append(\"Gamma=\"+str(g))\n",
    "  # print(\"data=\",data)\n",
    "# plt.boxplot(data,labels=l)\n",
    "# plt.show()\n",
    "\n",
    "  ax[int(g/3)][g%3].hist(prob,bins=5,range=(0,5))\n",
    "  ax[int(g/3)][g%3].set_title(\"Gamma=\"+str(g))\n",
    "ax[0][0].hist(penalty_cvar,bins=5,range=(0,5))\n",
    "ax[0][0].set_title(\"75%-CVaR\")\n",
    "plt.show()\n",
    "print(\"len=\",len(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 2]\n",
      " [5 1 0 2]\n",
      " [5 4 0 6]\n",
      " [5 6 3 6]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bc652a6662848c169ddaad7e75fc7966486f1f662e7670e7ffb2b305ef6abae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
